---
title: "On the L1-acquisition of discourse like - Part 4"
author: "Anonymous"
date: "`r format(Sys.time(), '%Y-%m-%d')`"
output:
  bookdown::html_document2: default
bibliography: bibliography.bib
link-citations: yes
---

This document shows an analysis that was performed with the aim of investigating the acquiasition of discourse *like* with modifying function in American English based on data from the *Child Language Data Exchange System* (CHILDES). The following represents part 4a of this analysis.

# Preparation

* Clean workspace
* Activate packages
* Set options
* Define paths

```{r likeac_4_01}
# clean workspace
rm(list=ls(all=T))
# load packages
library(tidyverse)
library(here)
library(partykit)
library(ggparty)
# set options
options(stringsAsFactors = F)
# read in data
data <- read.delim(here::here("datatables", "datadmlike.txt"), sep = "\t", header=TRUE, quote = "", skipNul = T)
# inspect data
glimpse(data)
```

Now, we read in the data.

```{r likeac_4_03}
data <- data %>%
  dplyr::rename(Child = File) %>%
  dplyr::mutate(Child = str_replace_all(Child, ".*/", "")) %>%
  dplyr::mutate(Child = str_sub(Child, 1, 3)) %>%
  na.omit()
# factorize variables
fctrs <- c("Child", "Gender", "SituationType", "Function", "Visit", "DiscourseLike")
data[fctrs] <- lapply(data[fctrs], factor)
# inspect data
head(data)
```


# Statistical Analysis

## Function-based Analysis

### CIT

```{r likeac_4_05}
# set.seed (to store random numbers and thus make results reproducible)
set.seed(2019120202) 
# create initial conditional inference tree model
citd.ctree <- partykit::ctree(Function ~ Age + Participants + Gender + SituationType + Like_Freq, data = data)
# extract p-values
pvals <- unlist(nodeapply(citd.ctree, ids = nodeids(citd.ctree), function(n) info_node(n)$p.value))
pvals <- pvals[pvals <.05]
# plotting
ggparty(citd.ctree) +
  geom_edge() +
  geom_edge_label() +
  geom_node_label(line_list = list(aes(label = splitvar),
                                   aes(label = paste0("N=", nodesize, ", p", 
                                                      ifelse(pvals < .001, "<.001", paste0("=", round(pvals, 3)))), 
                                       size = 10)),
                  line_gpar = list(list(size = 13), 
                                   list(size = 10)), 
                  ids = "inner") +
  geom_node_label(aes(label = paste0("Node ", id, ", N = ", nodesize)),
    ids = "terminal", nudge_y = 0.01, nudge_x = 0.01) +
  geom_node_plot(gglist = list(
    geom_bar(aes(x = "", fill = Function),
             position = position_dodge(), color = "black"),
    theme_minimal(),
    theme(panel.grid.major = element_blank(), 
          panel.grid.minor = element_blank(),
          legend.position = "bottom"),
      scale_fill_manual(values = c("gray80", "gray60", "gray40", "gray20")),
      scale_y_continuous(breaks = seq(0, 80, 20),
                         limits = c(0, 80)),
    xlab(""), 
    ylab("Frequency"),
      geom_text(aes(x = "", group = Function,
                    label = stat(count)),
                stat = "count", 
                position = position_dodge(0.9), vjust = -0.7)),
    shared_axis_labels = TRUE) +
  ggsave(file = here::here("images", "CIT.png"),
         height = 5,  width = 10, dpi = 320)
```


```{r likeac_4_07}
# plotting
ggparty(citd.ctree) +
  geom_edge() +
  geom_edge_label() +
  geom_node_label(line_list = list(aes(label = splitvar),
                                   aes(label = paste0("N=", nodesize, ", p", 
                                                      ifelse(pvals < .001, "<.001", paste0("=", round(pvals, 3)))), 
                                       size = 10)),
                  line_gpar = list(list(size = 13), 
                                   list(size = 10)), 
                  ids = "inner") +
  geom_node_label(aes(label = paste0("Node ", id, ", N = ", nodesize)),
    ids = "terminal", nudge_y = 0.01, nudge_x = 0.01) +
  geom_node_plot(gglist = list(
    geom_bar(aes(x = "", fill = Function),
             position = position_fill(), color = "black"),
    theme_minimal(),
    theme(panel.grid.major = element_blank(), 
          panel.grid.minor = element_blank(),
          legend.position = "bottom"),
      scale_fill_manual(values = c("gray80", "gray60", "gray40", "gray20")),
      scale_y_continuous(breaks = seq(0, 1, .2),
                         limits = c(0, 1)),
    xlab(""), 
    ylab("Probability")),
    shared_axis_labels = TRUE) +
  ggsave(file = here::here("images", "CIT_fill.png"),
         height = 5,  width = 10, dpi = 320)
```

### Boruta

We can now begin with the statistical analysis of discourse *like* with modifying function. In a first step, we perform a Boruta analysis as a variable selection procedure to check which variables have any type of meaningful relationship with the use of discourse *like* with modifying function.

```{r likeac_4_09}
# load library
library(Boruta)
# rename Like_freq
bdata <- data %>%
  dplyr::rename(LikeCaregiver = Like_Freq,
                AttentionFrequency = Att_Freq,
                SpecificationFrequency = Spe_Freq) %>%
  dplyr::select(-Visit)
# run 1
set.seed(20201120)
boruta1 <- Boruta(Function ~.,data=bdata)
print(boruta1)
```

We remove variables that are confirmed as being unimportant and rerun the analysis.

```{r likeac_4_11}
bdata <- bdata %>%
  dplyr::select(Function, names(boruta1$finalDecision)[which(boruta1$finalDecision != "Rejected")])
# run 2
set.seed(20201120)
boruta2 <- Boruta(Function ~.,data=bdata)
print(boruta2)
```

```{r likeac_4_13}
bdata <- bdata %>%
  dplyr::select(Function, names(boruta1$finalDecision)[which(boruta1$finalDecision == "Confirmed")])
# run 3
set.seed(20201120)
boruta3 <- Boruta(Function ~.,data=bdata)
print(boruta3)
```

We can visualize the results of the Boruta analysis.

```{r likeac_4_15}
library(ggplot2)
library(tidyr)
library(stringr)
borutadf <- as.data.frame(boruta3$ImpHistory) %>%
  gather(Variable, Importance, Age:shadowMin) %>%
  mutate(Type = ifelse(str_detect(Variable, "shadow"), "Control", "Predictor")) %>%
  mutate(Type = factor(Type),
         Variable = factor(Variable))
ggplot(borutadf, aes(x = reorder(Variable, Importance, mean), y = Importance, fill = Type)) + 
  geom_boxplot() +
  geom_vline(xintercept=3.5, linetype="dashed", color = "black") +
  scale_fill_manual(values = c("gray80", "gray40")) +
  theme_bw() + 
  theme(legend.position = "top",
        axis.text.x = element_text(angle=90)) +
  labs(x = "")
```

## Speaker-based analysis

```{r spb_dpro1}
# read in data
speakers <- read.delim(here::here("datatables", "speakers.txt"), sep = "\t", header=TRUE, quote = "", skipNul = T) %>%
  dplyr::mutate(DiscourseLike_Raw = DiscourseLike,
                DiscourseLike = round(DiscourseLike/WordCount*1000, 3),
                Attention_Raw = Attention,
                Attention = round(Attention/WordCount*1000, 3),
                Repair_Raw = Repair,
                Repair = round(Repair/WordCount, 3),
                Cognitive_Raw = Cognitive,
                Cognitive = round(Cognitive/WordCount*1000, 3),
                Specification_Raw = Specification,
                Specification = round(Specification/WordCount*1000, 3),
                Child = str_remove_all(File, ".*/"),
                Child = str_sub(Child, 1, 3)) %>%
  dplyr::filter(Cohort != "11-12",
                Locutor != "Other",
                Locutor != "Peer") %>%
  dplyr::select(-Speaker, -OriginalAge, - Cohort, -DateOfBirth, -DateOfRecording,
                -Attention_Raw, -Repair_Raw, -Cognitive_Raw, -Specification_Raw, 
                -AgeCategory, -SocioEconomicStatus, -Visit) %>%
  dplyr::rename(Speaker = Locutor) %>%
  dplyr::mutate(Child = factor(Child),
                Gender = factor(Gender),
                Speaker = factor(Speaker),
                SituationType = factor(SituationType),
                Situation = factor(Situation))
# inspect data
head(speakers)
```

## Discourse like by speaker

```{r spb_dpro2}
likespk <- speakers  %>%
  dplyr::select(-Attention, -Repair, -Cognitive, -Specification, -WordCount, -DiscourseLike_Raw)
# extract children's data
chi <- likespk%>%
  dplyr::filter(Speaker== "Child")
# extract caregiver's data
mot <- likespk%>%
  dplyr::filter(Speaker== "PrimaryCaregiver") %>%
  dplyr::select(File, DiscourseLike) %>%
  dplyr::rename(PrimaryCaregiver = DiscourseLike)
# combine chi and mot data
likespk <- dplyr::left_join(chi, mot, by = "File")
# inspect data
head(likespk)
```

### CIT


```{r likeac_4_17a}
# set.seed (to store random numbers and thus make results reproducible)
set.seed(2019120202) 
# create initial conditional inference tree model
citd.ctree <- partykit::ctree(DiscourseLike ~ Age + Participants + Gender + SituationType + PrimaryCaregiver, data = likespk)
# extract p-values
pvals <- unlist(nodeapply(citd.ctree, ids = nodeids(citd.ctree), function(n) info_node(n)$p.value))
pvals <- pvals[pvals <.05]
# plotting
ggparty(citd.ctree) +
  geom_edge() +
  geom_edge_label() +
  geom_node_label(line_list = list(aes(label = splitvar),
                                   aes(label = paste0("N=", nodesize, ", p", 
                                                      ifelse(pvals < .001, "<.001", paste0("=", round(pvals, 3)))), 
                                       size = 10)),
                  line_gpar = list(list(size = 13), 
                                   list(size = 10)), 
                  ids = "inner") +
  geom_node_label(aes(label = paste0("Node ", id, ", N = ", nodesize)),
    ids = "terminal", nudge_y = 0.01, nudge_x = 0.01) +
  geom_node_plot(gglist = list(
#    geom_boxplot(aes(x = "", y = DiscourseLike)),
    stat_summary(aes(x = "", y = DiscourseLike), fun = mean, geom = "point"),
    stat_summary(aes(x = "", y = DiscourseLike), fun.data = mean_cl_boot,
                 geom = "errorbar", width = 0.2),
    theme_minimal(),
    theme(#panel.grid.major = element_blank(), 
          panel.grid.minor = element_blank(),
          legend.position = "bottom",
          plot.margin = margin(.1, .1, .1, .1, "cm"),),
      scale_y_continuous(breaks = seq(0, 10, 2), limits = c(0, 10)),
    xlab(""), 
    ylab("Frequency\n(per 1,000 words)")),
    shared_axis_labels = TRUE) +
  ggsave(file = here::here("images", "CIT_spk.png"),
         height = 7,  width = 12, dpi = 320)
```

```{r likeac_4_17b}
plot(citd.ctree)
```

```{r spb_dpro3}
test <- likespk %>%
  dplyr::select(Age, DiscourseLike) %>%
  dplyr::filter(Age > 8.94) %>%
  dplyr::summarize(DiscourseLike = mean(DiscourseLike),
          N = length(Age))
test
```



## Functions by speaker

```{r spb_dpro3}
funspk <- speakers %>%
  dplyr::select(-DiscourseLike, -DiscourseLike_Raw, -WordCount) %>%
  tidyr::gather(Function, Frequency, Attention:Specification) %>%
  dplyr::mutate(Function = factor(Function))
# extract children's data
chi_fun <- funspk %>%
  dplyr::filter(Speaker == "Child")
# extract caregiver's data
mot_fun <- funspk %>%
  dplyr::filter(Speaker == "PrimaryCaregiver") %>%
  dplyr::select(File, Function, Frequency) %>%
  dplyr::rename(PrimaryCaregiver = Frequency)
# combine data
funspk <- dplyr::left_join(chi_fun, mot_fun, by = c("File", "Function"))
# inspect data
head(funspk)
```


### CIT


```{r likeac_4_19}
# set.seed (to store random numbers and thus make results reproducible)
set.seed(2019120202) 
# create initial conditional inference tree model
citd.ctree <- partykit::ctree(Frequency ~ Function + Age + Participants + Gender + SituationType + PrimaryCaregiver, data = funspk)
# extract p-values
pvals <- unlist(nodeapply(citd.ctree, ids = nodeids(citd.ctree), function(n) info_node(n)$p.value))
pvals <- pvals[pvals <.05]
# plotting
ggparty(citd.ctree) +
  geom_edge() +
  geom_edge_label() +
  geom_node_label(line_list = list(aes(label = splitvar),
                                   aes(label = paste0("N=", nodesize, ", p", 
                                                      ifelse(pvals < .001, "<.001", paste0("=", round(pvals, 3)))), 
                                       size = 10)),
                  line_gpar = list(list(size = 13), 
                                   list(size = 10)), 
                  ids = "inner") +
  geom_node_label(aes(label = paste0("Node ", id, ", N = ", nodesize)),
    ids = "terminal", nudge_y = 0.01, nudge_x = 0.01) +
  geom_node_plot(gglist = list(
    stat_summary(aes(x = Function, y = Frequency, group = Function), fun = mean, geom = "point"),
    stat_summary(aes(x = Function, y = Frequency, group = Function), fun.data = mean_cl_boot,
                 geom = "errorbar", width = 0.2),
    theme_minimal(),
    theme(panel.grid.minor = element_blank(),
          legend.position = "bottom"),
      scale_y_continuous(breaks = seq(0, 5, 1), limits = c(0, 5)),
    xlab(""), 
    ylab("Frequency\n(per 1,000 words)")),
    shared_axis_labels = TRUE) +
  ggsave(file = here::here("images", "CIT_funspk.png"),
         height = 5,  width = 10, dpi = 320)
```


# Extract tables

Reload speaker data

```{r likeac_4_23}
# read in data
speakers <- read.delim(here::here("datatables", "speakers.txt"), sep = "\t", header=TRUE, quote = "", skipNul = T) %>%
  dplyr::mutate(DiscourseLike_Raw = DiscourseLike,
                DiscourseLike = round(DiscourseLike/WordCount*1000, 3),
                Attention_Raw = Attention,
                Attention = round(Attention/WordCount*1000, 3),
                Repair_Raw = Repair,
                Repair = round(Repair/WordCount, 3),
                Cognitive_Raw = Cognitive,
                Cognitive = round(Cognitive/WordCount*1000, 3),
                Specification_Raw = Specification,
                Specification = round(Specification/WordCount*1000, 3),
                Child = str_remove_all(File, ".*/"),
                Child = str_sub(Child, 1, 3)) %>%
  dplyr::filter(Cohort != "11-12",
                Locutor != "Other",
                Locutor != "Peer") %>%
  dplyr::select(-Speaker, -OriginalAge, - Cohort, -DateOfBirth, -DateOfRecording,
                -Attention_Raw, -Repair_Raw, -Cognitive_Raw, -Specification_Raw, 
                -AgeCategory, -SocioEconomicStatus, -Visit) %>%
  dplyr::rename(Speaker = Locutor) %>%
  dplyr::mutate(Child = factor(Child),
                Gender = factor(Gender),
                Speaker = factor(Speaker),
                SituationType = factor(SituationType),
                Situation = factor(Situation))
# inspect data
head(speakers)
```


```{r likeac_4_21a}
Table1a <- speakers %>%
  dplyr::select(File, Speaker, SituationType, Age, 
                WordCount, DiscourseLike_Raw) %>%
  dplyr::filter(Speaker == "Child") %>%
  dplyr::mutate(SpeakerID = str_replace_all(File, ".*/", ""),
                SpeakerID = substr(SpeakerID, 1, 3),
                SpeakerID = paste0(SpeakerID, Speaker),
                SpeakerID = factor(SpeakerID),
                Cohort = dplyr::case_when(Age < 5 ~ "3-4",
                                          Age < 7 ~ "5-6",
                                          Age < 9 ~ "7-8",
                                          Age < 11 ~ "9-10",
                                          Age < 13 ~ "11-12")) %>%
  dplyr::select(-File, -Age) %>%
  dplyr::group_by(Speaker, SituationType, Cohort, SpeakerID) %>%
  dplyr::summarise(Words = sum(WordCount),
                   Like = sum(DiscourseLike_Raw),
                   Speakers = n()) %>%
  dplyr::ungroup() %>%
  dplyr::group_by(Speaker, SituationType, Cohort) %>%
  dplyr::summarise(Words = sum(Words),
                   Like = sum(Like),
                   Speakers = n()) %>%
  dplyr::mutate(Frequency = round(Like/Words*1000, 2)) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(Speaker = factor(Speaker),
                SituationType = factor(SituationType),
                Cohort = factor(Cohort)) %>%
  dplyr::arrange(Speaker, Cohort, SituationType)
# create total
Total <-c("Total",
          "",
          "",
          sum(Table1a$Words),
          sum(Table1a$Like),
          "",
          round(sum(Table1a$Like)/sum(Table1a$Words)*1000, 2))
Table1a <- rbind(Table1a, Total)
# save data to disc
write.table(Table1a, file = here::here("tables", "Table1a.txt"), sep = "\t",
            row.names = FALSE, col.names = TRUE, quote = F)
# inspect data
Table1a
```


```{r likeac_4_21b}
Table1b <- speakers %>%
  dplyr::select(File, Speaker, SituationType, Age, 
                WordCount, DiscourseLike_Raw) %>%
  dplyr::filter(Speaker != "Child") %>%
  dplyr::mutate(SpeakerID = str_replace_all(File, ".*/", ""),
                SpeakerID = substr(SpeakerID, 1, 3),
                SpeakerID = paste0(SpeakerID, Speaker),
                SpeakerID = factor(SpeakerID),
                Cohort = dplyr::case_when(Age < 5 ~ "3-4",
                                          Age < 7 ~ "5-6",
                                          Age < 9 ~ "7-8",
                                          Age < 11 ~ "9-10",
                                          Age < 13 ~ "11-12")) %>%
  dplyr::select(-File, -Age) %>%
  dplyr::group_by(Speaker, SituationType, Cohort, SpeakerID) %>%
  dplyr::summarise(Words = sum(WordCount),
                   Like = sum(DiscourseLike_Raw),
                   Speakers = n()) %>%
  dplyr::ungroup() %>%
  dplyr::group_by(Speaker, SituationType, Cohort) %>%
  dplyr::summarise(Words = sum(Words),
                   Like = sum(Like),
                   Speakers = n()) %>%
  dplyr::mutate(Frequency = round(Like/Words*1000, 2)) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(Speaker = factor(Speaker),
                SituationType = factor(SituationType),
                Cohort = factor(Cohort)) %>%
  dplyr::arrange(Speaker, Cohort, SituationType)
# create total
Total <-c("Total",
          "",
          "",
          sum(Table1b$Words),
          sum(Table1b$Like),
          "",
          round(sum(Table1b$Like)/sum(Table1b$Words)*1000, 2))
Table1b <- rbind(Table1b, Total)
# save data to disc
write.table(Table1a, file = here::here("tables", "Table1b.txt"), sep = "\t",
            row.names = FALSE, col.names = TRUE, quote = F)
# inspect data
Table1b
```

```{r likeac_4_21b}
Table1 <- rbind(Table1a, Table1b)
# save data to disc
write.table(Table1, file = here::here("tables", "Table1.txt"), sep = "\t",
            row.names = FALSE, col.names = TRUE, quote = F)
# inspect data
Table1
```

```{r likeac_4_25}
visits <- str_remove_all(speakers$File, "/.*")
visits <- str_remove_all(visits, "[A-Z]{1,}")
table(visits)
```

```{r likeac_4_27}
gender <- speakers %>%
  dplyr::select(Child, Speaker, Gender) %>%
  dplyr::filter(Speaker == "Child") %>%
  dplyr::group_by(Child) %>%
  dplyr::summarise(Gender = unique(Gender))
table(gender$Gender)
```

```{r likeac_4_29}
Table3 <- data %>%
    dplyr::select(Child, SituationType, Age, 
                Function, DiscourseLike) %>%
  dplyr::mutate(Id = 1:nrow(data),
                Cohort = dplyr::case_when(Age < 5 ~ "3-4",
                                          Age < 7 ~ "5-6",
                                          Age < 9 ~ "7-8",
                                          Age < 11 ~ "9-10",
                                          Age < 13 ~ "11-12")) %>%
  tidyr::spread(Function, DiscourseLike) %>%
  dplyr::mutate(Attention = tidyr::replace_na(as.numeric(Attention), 0),
                Cognitive = tidyr::replace_na(as.numeric(Cognitive), 0),
                Repair = tidyr::replace_na(as.numeric(Repair), 0),
                Specification = tidyr::replace_na(as.numeric(Specification), 0)) %>%
  dplyr::group_by(Cohort, SituationType) %>%
  dplyr::summarise(Children = length(names(table(Child)[which(table(Child) > 0)])),
                   Attention = sum(Attention),
                   Cognitive = sum(Cognitive),
                   Repair = sum(Repair),
                   Specification = sum(Specification)) %>%
  dplyr::rowwise() %>%
  dplyr::mutate(All = Attention+Cognitive+Repair+Specification,
                Attention_p = round(Attention/All*100, 1),
                Cognitive_p = round(Cognitive/All*100, 1),
                Repair_p = round(Repair/All*100, 1),
                Specification_p = round(Specification/All*100, 1)) %>%
  dplyr::mutate(Attention = paste0(Attention, " (", Attention_p, ")"),
                Cognitive = paste0(Cognitive, " (", Cognitive_p, ")"),
                Repair = paste0(Repair, " (", Repair_p, ")"),
                Specification = paste0(Specification, " (", Specification_p, ")")) %>%
  dplyr::select(-All, -Attention_p, -Cognitive_p, -Repair_p, -Specification_p)
# save data to disc
write.table(Table3, file = here::here("tables", "Table3.txt"), sep = "\t",
            row.names = FALSE, col.names = TRUE, quote = F)
# inspect data
Table3
```

```{r likeac_4_31}

```


## Extract session information

```{r}
sessionInfo()
```


***

We have reached the end of Part 4 of the analysis.

***



