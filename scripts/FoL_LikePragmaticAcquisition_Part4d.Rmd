---
title: "On the L1-acquisition of discourse like - Part 4d"
author: "Anonymous"
date: "`r format(Sys.time(), '%Y-%m-%d')`"
output:
  bookdown::html_document2: default
bibliography: bibliography.bib
link-citations: yes
---

This document shows an analysis that was performed with the aim of investigating the acquisition of discourse *like* indicating lexical indecision in American English based on data from the *Child Language Data Exchange System* (CHILDES). The following lexresents part 4d of this analysis.

In a first step, we prepare the session by cleaning the workspace, loading packages, setting options, and defining paths.

```{r likeac_4d_001, echo=T, eval = T, message=FALSE, warning=FALSE}
# clean workspace
rm(list=ls(all=T))
# load packages
library(dplyr)
# set options
options(stringsAsFactors = F)
# define image directory
imageDirectory<-"images"
```

Now, we read in the data.

```{r likeac_4d_002, echo=T, eval = T, message=FALSE, warning=FALSE}
# read in data
lex <- read.delim("datatables/lex.txt", sep = "\t", 
                   header=TRUE, quote = "", skipNul = T)
# factorize variables
fctrs <- c("Child", "Gender", "Participants", "LexicalIndecision", "SituationType")
lex[fctrs] <- lapply(lex[fctrs], factor)
# create boruta data set
borutalex <- lex
# inlexct data
head(lex)
```

We can now begin with the statistical analysis of discourse *like* with lexcifying function. In a first step, we perform a Boruta analysis as a variable selection procedure to check which variables have any type of meaningful relationship with the use of discourse *like* with lexifying function.

```{r likeac_4d_003, echo=T, eval = T, message=FALSE, warning=FALSE}
# load library
library(Boruta)
# run 1
boruta.lex <- Boruta(LexicalIndecision ~.,data=borutalex)
print(boruta.lex)
```

We remove variables that are confirmed as being unimportant and rerun the analysis.

```{r likeac_4d_004, echo=T, eval = T, message=FALSE, warning=FALSE}
borutalex <- borutalex %>%
  dplyr::select(-Lex_Freq)
# run 2
boruta.lex <- Boruta(LexicalIndecision ~.,data=borutalex)
print(boruta.lex)
```

We can visualize the results of the Boruta analysis.

```{r likeac_4d_005, echo=T, eval = T, message=FALSE, warning=FALSE}
plot(boruta.lex)
```

We can now proceed with the regression analysis.

```{r likeac_4d_006, echo=T, eval = T, message=FALSE, warning=FALSE}
# load packages
library(lme4)
library(car)
library(rms)
# set options
options(contrasts  =c("contr.treatment", "contr.poly"))
data.dist <- datadist(lex)
options(datadist = "data.dist")
# create base glm line model
m0.glm = glm(LexicalIndecision ~ 1, data = lex, family = binomial)
# create base glmm line model
m0.glmer = glmer(LexicalIndecision ~ (1|Child), data = lex, family = binomial, 
                  control=glmerControl(optimizer="bobyqa"))
# compare AICs
aic.glmer<- AIC(logLik(m0.glmer))
aic.glm <- AIC(logLik(m0.glm))
aic.glmer; aic.glm
```

```{r likeac_4d_007, echo=T, eval = T, message=FALSE, warning=FALSE}
# test random effects
null.id = -2 * logLik(m0.glm) + 2 * logLik(m0.glmer)
pchisq(as.numeric(null.id), df=1, lower.tail=F) 
```

The glmm only has a marginally significantly better model fit compared to the glm model. We retain Child as a random effect as the data is herarchical and because the other modesl confirmed Child as being significant. We now check if Age is a significant predictor for lexifying uses of discourse *like*.

```{r likeac_4d_008, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Age
m1.glm <- update(m0.glm, .~.+Age)
m1.glmer <- update(m0.glmer, .~.+Age)
anova(m1.glmer, m0.glmer, test = "Chi")     
Anova(m1.glmer, type = "III", test = "Chi")   
```

As Age is not significant, we do not retain it in the model and proceed by adding Gender.

```{r likeac_4b_009, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Gender
ifelse(min(ftable(lex$Gender, lex$LexicalIndecision)) == 0, "not possible", "possible")
m2.glm <- update(m0.glm, .~.+Gender)
vif(m2.glm)
m2.glmer <- update(m0.glmer, .~.+Gender)
anova(m2.glmer, m0.glmer, test = "Chi")     
Anova(m2.glmer, type = "III", test = "Chi")   
```

As Gender is not significant, we do not retain it in the model and proceed by adding SituationType.

```{r likeac_4b_010, echo=T, eval = T, message=FALSE, warning=FALSE}
# add SituationType
ifelse(min(ftable(lex$SituationType, lex$LexicalIndecision)) == 0, "not possible", "possible")
m3.glm <- update(m0.glm, .~.+SituationType)
vif(m3.glm)
m3.glmer <- update(m0.glmer, .~.+SituationType)
anova(m3.glmer, m0.glmer, test = "Chi")     
Anova(m3.glmer, type = "III", test = "Chi")   
```

As SituationType is significant, we retain it in the model and proceed by adding Like_Freq.

```{r likeac_4b_011, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Like_Freq
m4.glm <- update(m3.glm, .~.+Like_Freq)
vif(m4.glm)
m4.glmer <- update(m3.glmer, .~.+Like_Freq)
anova(m4.glmer, m3.glmer, test = "Chi")      
```

As Like_Freq is not significant, we do not retain it in the model and proceed by adding Participants.

```{r likeac_4b_012, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Participants
m5.glm <- update(m3.glm, .~.+ Participants)
vif(m5.glm)
m5.glmer <- update(m3.glmer, .~.+ Participants)
anova(m5.glmer, m3.glmer, test = "Chi")       
```

As Participants is not significant, we do not retain it in the model and proceed by adding all secondary or two-way interactions. We begin by adding Age*Gender.

```{r likeac_4b_013, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Age*Gender
m6.glm <- update(m3.glm, .~.+ Age*Gender)
vif(m6.glm)
m6.glmer <- update(m3.glmer, .~.+ Age*Gender)
anova(m6.glmer, m3.glmer, test = "Chi")      
```

As the interaction between Age and Gender is not significant, we do not retain it in the model and proceed by adding the interaction between Age and SituationType.

```{r likeac_4b_014, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Age*SituationType
m7.glm <- update(m3.glm, .~.+ Age*SituationType)
vif(m7.glm)
m7.glmer <- update(m3.glmer, .~.+ Age*SituationType)
anova(m7.glmer, m3.glmer, test = "Chi")
Anova(m7.glmer, type = "III", test = "Chi") 
```

Adding the interaction between Age and SituationType is not significant, we do not retain it in the model and proceed by adding the interaction between Age and Like_Freq.

```{r likeac_4b_015, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Age*Like_Freq
m8.glm <- update(m3.glm, .~.+ Age*Like_Freq)
vif(m8.glm)
m8.glmer <- update(m3.glmer, .~.+ Age*Like_Freq)
anova(m8.glmer, m3.glmer, test = "Chi")     
Anova(m8.glmer, type = "III", test = "Chi")   
```

The interaction between Age and Like_Freq is not significant and we do not retain it in the model. We proceed by adding the interaction between Age and Participants.

```{r likeac_4b_016, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Age*Participants
m9.glm <- update(m3.glm, .~.+ Age*Participants)
vif(m9.glm)
```

The interaction between Age and Participants leads to unacceptable collinearity and we thus do not include it in the model. We proceed by adding the interaction between Gender and SituationType.

```{r likeac_4b_017, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Gender*SituationType
m10.glm <- update(m3.glm, .~.+ Gender*SituationType)
vif(m10.glm)
m10.glmer <- update(m3.glmer, .~.+ Gender*SituationType)
anova(m10.glmer, m3.glmer, test = "Chi")     
```

The interaction between Gender and SituationType is not significant and we thus do not retain it in the model. We proceed by adding the interaction between Gender and Like_Freq.

```{r likeac_4b_018, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Gender*Like_Freq
m11.glm <- update(m3.glm, .~.+ Gender*Like_Freq)
vif(m11.glm)
m11.glmer <- update(m3.glmer, .~.+ Gender*Like_Freq)
anova(m11.glmer, m3.glmer, test = "Chi")     
```

The interaction between Gender and Like_Freq is not significant and we thus do not retain it in the model. We proceed by adding the interaction between Gender and Participants.

```{r likeac_4b_019, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Gender*Participants
m12.glm <- update(m3.glm, .~.+ Gender*Participants)
vif(m12.glm)
m12.glmer <- update(m3.glmer, .~.+ Gender*Participants)
anova(m12.glmer, m3.glmer, test = "Chi")       
```

The interaction between Gender and Participants is not significant and we thus do not retain it in the model. We proceed by adding the interaction between SituationType and Like_Freq.

```{r likeac_4b_020, echo=T, eval = T, message=FALSE, warning=FALSE}
# add SituationType*Like_Freq
m13.glm <- update(m3.glm, .~.+ SituationType*Like_Freq)
vif(m13.glm)
m13.glmer <- update(m3.glmer, .~.+ SituationType*Like_Freq)
anova(m13.glmer, m3.glmer, test = "Chi")     
Anova(m13.glmer, type = "III", test = "Chi")   
```

The interaction between SituationType and Like_Freq is significant and we thus retain it in the model.  We proceed by adding the interaction between SituationType and Participants.

```{r likeac_4b_021, echo=T, eval = T, message=FALSE, warning=FALSE}
# add SituationType*Participants
m14.glm <- update(m13.glm, .~.+ SituationType*Participants)
vif(m14.glm)
m14.glmer <- update(m13.glmer, .~.+ SituationType*Participants)
anova(m14.glmer, m13.glmer, test = "Chi")     
Anova(m14.glmer, type = "III", test = "Chi")   
```

The interaction between SituationType and Participants is not significant (on the variable level) and we thus do not retain it in the model.  We proceed by adding the interaction between Like_Freq and Participants.

```{r likeac_4b_022, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Like_Freq*Participants
m15.glm <- update(m13.glm, .~.+ Like_Freq*Participants)
vif(m15.glm)
m15.glmer <- update(m13.glmer, .~.+ Like_Freq*Participants)
anova(m15.glmer, m13.glmer, test = "Chi")      
```

The interaction between Like_Freq and Participants  is not significant and we thus do not retain it in the model. We have arrived at a minimal adequate model and proceed with model diagnostics and create the diagnostic plots. We have arrived at a minimal adequate model and proceed with model diagnostics and create the diagnostic plots.

```{r likeac_4d_023, echo=T, eval = T, message=FALSE, warning=FALSE}
# start plotting
plot(m13.glmer, pch = 20, col = "black")         
```

We now check if the data contains data points that have an unacceptably high impact on the model by plotting the Cook's distance. To plot Cook's Distance, we create a glm object which also contains Turn as a predictor as it is included in the final glmer model in the random effect structure. This way, the predictions of the glm and the glmar model are identical.

```{r likeac_4d_024, echo=T, eval = T, message=FALSE, warning=FALSE}
m13b.glm <- update(m13.glm, .~.+ Child)
# determine a cutoff for data points that have D-values higher than 4/(n-k-1) 
cutoff <- 4/((nrow(lex)-length(m13b.glm$coefficients)-2))
cutoff
```

The Cook's distance plot names three data points that may cause issues. Also, if we apply the data driven cutoff for Cook's distance (0.001814882), we would retain only 55 data points which is unacceptable. 

We thus have to adapt the cutoff manually and plot the cook's distance values. 

```{r likeac_4d_025, echo=T, eval = T, message=FALSE, warning=FALSE}
# plot cook*s distance
plot(m13b.glm, which=4, cook.levels = cutoff) 
```

There are three 3 data points that are suggested as potential outlierswhich is why we add influence statistics to our data to get some more information about data points that may require removing.

```{r likeac_4d_026, echo=T, eval = T, message=FALSE, warning=FALSE}
# extract influence statistics
infl <- influence.measures(m13b.glm)       
# add infl. statistics to data
lex <- data.frame(lex, infl[[1]], infl[[2]]) 
```

We now add an index to the data to better identify problematic data points. Then, we order the data by the Cook's distance values and display the data to inlexct the data points with the highest Cook's distance.

```{r likeac_4d_027, echo=T, eval = T, message=FALSE, warning=FALSE}
# create index for data
lex$id <- 1:nrow(lex)
lex <- lex[order(lex$cook.d, decreasing = T),]
head(lex)
```

The diagnostics do not indicate that we have to remove data points as, overall, the Cook's distance is distributed  evenly and we proceed by extracting the model statistics, adding them to the data set, and creating additional model diagnostic plots. 

```{r likeac_4d_028, echo=T, eval = T, message=FALSE, warning=FALSE}
# add diagnostics
lex$residuals <- resid(m13b.glm)
lex$standardized.residuals <- rstandard(m13b.glm)
lex$studentized.residuals <- rstudent(m13b.glm)
lex$cooks.distance <- cooks.distance(m13b.glm)
lex$dffit <- dffits(m13b.glm)
lex$leverage <- hatvalues(m13b.glm)
lex$covariance.ratios <- covratio(m13b.glm)
lex$fitted <- m13b.glm$fitted.values
# plot diagnostics
p1 <- ggplot(lex, 
              aes(studentized.residuals)) +
  theme(legend.position = "none") +
  theme_set(theme_bw(base_size = 8))+ 
  geom_histogram(aes(y=..density..),
                 binwidth = 1,
                 colour="black",
                 fill="white") +
  labs(x = "Studentized Residual", y = "Density") + 
  stat_function(fun = dnorm, 
                args = list(mean = mean(lex$studentized.residuals, na.rm = TRUE), 
                            sd = sd(lex$studentized.residuals, na.rm = TRUE)), 
                colour = "red", size = 1)
p1
```

The diagnostic plots confirms that we will have to remove data points. To identify these points, we plot the fitted values against the studentized residuals.

```{r likeac_4d_029, echo=T, eval = T, message=FALSE, warning=FALSE}
# plot diagnostics
p2 <- ggplot(lex, aes(fitted, studentized.residuals)) +
  geom_point() + 
  geom_smooth(method = "lm", colour = "Red")+
  theme_set(theme_bw(base_size = 8))+ 
  labs(x = "Fitted Values", 
       y = "Studentized Residual")
p2
```

```{r likeac_4d_030, echo=T, eval = T, message=FALSE, warning=FALSE}
# plot diagnostics
p3 <- qplot(sample = lex$studentized.residuals, stat="qq") + 
  theme_set(theme_bw(base_size = 8))+ 
  labs(x = "Theoretical Values", 
       y = "Observed Values")
p3
```

```{r likeac_4d_031, echo=T, eval = T, message=FALSE, warning=FALSE}
lex <- lex %>%
  dplyr::arrange(studentized.residuals)
# inlexct reordered data
lex[1:10, c(ncol(lex)-5:ncol(lex))]; lex[c(nrow(lex)-5:nrow(lex)), c(ncol(lex)-5:ncol(lex))]
```

We have now identified the problematic data points which are the points that have the IDs 324 as well as 207, 1, 24, 169, 163, 123, and 8. We remove these points as well as the diagnostic values and lexeat the analysis.

```{r likeac_4d_032, echo=T, eval = T, message=FALSE, warning=FALSE}
rmv <- c(324, 207, 1, 24, 169, 163, 123, 8)
# define not in
`%notin%` <- Negate(`%in%`)
lex <- lex %>%
  dplyr::filter(id %notin% rmv) %>%
  # remove diagnostic statistics
  dplyr::select(-dfb.1_, -dfb.SttT, -dfb.Lk_F, -dfb.Childl, -dfb.Chldll,
                -dfb.Chldnn, -dfb.Childst, -dfb.Chldbb, -dfb.Childbra,
                -dfb.Childbri, -dfb.Chldbrn, -dfb.Chldcs, -dfb.Chldcl,
                -dfb.Chldcn, -dfb.Chldct, -dfb.Childdav, -dfb.Childdev,
                -dfb.Childd, -dfb.Chldth, -dfb.Childg, -dfb.Chldgr, 
                -dfb.Childn, -dfb.Chldjc, -dfb.Chldjm, -dfb.Childje,
                -dfb.Chldjb, -dfb.Chldjn, -dfb.Chldjr, -dfb.Childjes,
                -dfb.Childjo, -dfb.Chldjy, -dfb.Childjus, -dfb.Childkar,
                -dfb.Chldkv, -dfb.Childkur, -dfb.Childmr, -dfb.Chldmy,
                -dfb.Chldmg, -dfb.Chldml, -dfb.Chldmn, -dfb.Chldmrk,
                -dfb.Childp, -dfb.Chldpt, -dfb.Childras, -dfb.Chldrm,
                -dfb.Chldrl, -dfb.Chldrc, -dfb.Childros, -dfb.Chldsr,
                -dfb.Chldstn, -dfb.Chldss, -dfb.Chldtd, -dfb.Chldtm,
                -dfb.Chldtr, -dfb.Chldv, -dfb.Chldz, -dfb.ST.L, -dffit, 
                -cov.r, -cook.d, -hat, -dfb.1_.1, -dfb.SttT.1, -dfb.Lk_F.1,
                -dfb.Childl.1, -dfb.Chldll.1, -dfb.Chldnn.1, -dfb.Childst.1,
                -dfb.Chldbb.1, -dfb.Childbra.1, -dfb.Childbri.1, 
                -dfb.Chldbrn.1, -dfb.Chldcs.1, -dfb.Chldcl.1, -dfb.Chldcn.1,
                -dfb.Chldct.1, -dfb.Childdav.1, -dfb.Childdev.1, -dfb.Childd.1,
                -dfb.Chldth.1, -dfb.Childg.1, -dfb.Chldgr.1, -dfb.Childn.1,
                -dfb.Chldjc.1, -dfb.Chldjm.1, -dfb.Childje.1, -dfb.Chldjb.1,
                -dfb.Chldjn.1, -dfb.Chldjr.1, -dfb.Childjes.1, -dfb.Childjo.1,
                -dfb.Chldjy.1, -dfb.Childjus.1, -dfb.Childkar.1, -dfb.Chldkv.1,
                -dfb.Childkur.1, -dfb.Childmr.1, -dfb.Chldmy.1, -dfb.Chldmg.1,
                -dfb.Chldml.1, -dfb.Chldmn.1, -dfb.Chldmrk.1, -dfb.Childp.1,
                -dfb.Chldpt.1, -dfb.Childras.1, -dfb.Chldrm.1, -dfb.Chldrl.1,
                -dfb.Chldrc.1, -dfb.Childros.1, -dfb.Chldsr.1, -dfb.Chldstn.1,
                -dfb.Chldss.1, -dfb.Chldtd.1, -dfb.Chldtm.1, -dfb.Chldtr.1,
                -dfb.Chldv.1, -dfb.Chldz.1, -dfb.ST.L.1, -dffit.1, -cov.r.1,
                -cook.d.1, -hat.1, -id, -residuals, -standardized.residuals,
                -studentized.residuals, -cooks.distance, -leverage,
                -covariance.ratios, -fitted)
```

We now lexeat the analysis and begin by creating another boruta data set.

```{r likeac_4d_033, echo=T, eval = T, message=FALSE, warning=FALSE}
# create boruta data set
borutalex <- lex
# inlexct data
head(lex)
```

We can now begin with the statistical analysis of discourse *like* with lexifying function. In a first step, we perform a Boruta analysis as a variable selection procedure to check which variables have any type of meaningful relationship with the use of discourse *like* with lexifying function.

```{r likeac_4d_034, echo=T, eval = T, message=FALSE, warning=FALSE}
# load library
library(Boruta)
# run 1
boruta.lex <- Boruta(LexicalIndecision ~.,data=borutalex)
print(boruta.lex)
```

We remove variables that are confirmed as being unimportant and rerun the analysis.

```{r likeac_4d_035, echo=T, eval = T, message=FALSE, warning=FALSE}
borutalex <- borutalex %>%
  dplyr::select(-Lex_Freq)
# run 2
boruta.lex <- Boruta(LexicalIndecision ~.,data=borutalex)
print(boruta.lex)
```

We can visualize the results of the Boruta analysis.

```{r likeac_4d_036, echo=T, eval = T, message=FALSE, warning=FALSE}
plot(boruta.lex)
```

We can now proceed with the regression analysis.

```{r likeac_4d_037, echo=T, eval = T, message=FALSE, warning=FALSE}
# set options
options(contrasts  =c("contr.treatment", "contr.poly"))
data.dist <- datadist(lex)
options(datadist = "data.dist")
# create base glm line model
m0.glm = glm(LexicalIndecision ~ 1, data = lex, family = binomial)
# create base glmm line model
m0.glmer = glmer(LexicalIndecision ~ (1|Child), data = lex, family = binomial, 
                  control=glmerControl(optimizer="bobyqa"))
# compare AICs
aic.glmer<- AIC(logLik(m0.glmer))
aic.glm <- AIC(logLik(m0.glm))
aic.glmer; aic.glm
```

```{r likeac_4d_038, echo=T, eval = T, message=FALSE, warning=FALSE}
# test random effects
null.id = -2 * logLik(m0.glm) + 2 * logLik(m0.glmer)
pchisq(as.numeric(null.id), df=1, lower.tail=F) 
```

The glmm has a significantly better model fit compared to the glm model. We now check if Age is a significant predictor for lexifying uses of discourse *like*.

```{r likeac_4d_039, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Age
m1.glm <- update(m0.glm, .~.+Age)
m1.glmer <- update(m0.glmer, .~.+Age)
anova(m1.glmer, m0.glmer, test = "Chi")      
```

As Age is not significant, we do not retain it in the model and proceed by adding Gender.

```{r likeac_4b_040, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Gender
ifelse(min(ftable(lex$Gender, lex$LexicalIndecision)) == 0, "not possible", "possible")
m2.glm <- update(m0.glm, .~.+Gender)
vif(m2.glm)
m2.glmer <- update(m0.glmer, .~.+Gender)
anova(m2.glmer, m0.glmer, test = "Chi")     
Anova(m2.glmer, type = "III", test = "Chi")   
```

As Gender is not significant, we do not retain it in the model and proceed by adding SituationType.

```{r likeac_4b_041, echo=T, eval = T, message=FALSE, warning=FALSE}
# add SituationType
ifelse(min(ftable(lex$SituationType, lex$LexicalIndecision)) == 0, "not possible", "possible")
m3.glm <- update(m0.glm, .~.+SituationType)
vif(m3.glm)
m3.glmer <- update(m0.glmer, .~.+SituationType)
anova(m3.glmer, m0.glmer, test = "Chi")     
Anova(m3.glmer, type = "III", test = "Chi")   
```

As SituationType is significant, we retain it in the model and proceed by adding Like_Freq.

```{r likeac_4b_042, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Like_Freq
m4.glm <- update(m3.glm, .~.+Like_Freq)
vif(m4.glm)
m4.glmer <- update(m3.glmer, .~.+Like_Freq)
anova(m4.glmer, m3.glmer, test = "Chi")      
```

As Like_Freq is not significant, we do not retain it in the model and proceed by adding Participants.

```{r likeac_4b_043, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Participants
m5.glm <- update(m3.glm, .~.+ Participants)
vif(m5.glm)
m5.glmer <- update(m3.glmer, .~.+ Participants)
anova(m5.glmer, m3.glmer, test = "Chi")       
```

As Participants is not significant, we do not retain it in the model and proceed by adding all secondary or two-way interactions. We begin by adding Age*Gender.

```{r likeac_4b_044, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Age*Gender
m6.glm <- update(m3.glm, .~.+ Age*Gender)
vif(m6.glm)
m6.glmer <- update(m3.glmer, .~.+ Age*Gender)
anova(m6.glmer, m3.glmer, test = "Chi")      
```

As the interaction between Age and Gender is not significant, we do not retain it in the model and proceed by adding the interaction between Age and SituationType.

```{r likeac_4b_045, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Age*SituationType
m7.glm <- update(m3.glm, .~.+ Age*SituationType)
vif(m7.glm)
m7.glmer <- update(m3.glmer, .~.+ Age*SituationType)
anova(m7.glmer, m3.glmer, test = "Chi")
Anova(m7.glmer, type = "III", test = "Chi") 
```

Adding the interaction between Age and SituationType is not significant, we do not retain it in the model and proceed by adding the interaction between Age and Like_Freq.

```{r likeac_4b_046, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Age*Like_Freq
m8.glm <- update(m3.glm, .~.+ Age*Like_Freq)
vif(m8.glm)
m8.glmer <- update(m3.glmer, .~.+ Age*Like_Freq)
anova(m8.glmer, m3.glmer, test = "Chi")      
```

The interaction between Age and Like_Freq is not significant and we do not retain it in the model. We proceed by adding the interaction between Age and Participants.

```{r likeac_4b_047, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Age*Participants
m9.glm <- update(m3.glm, .~.+ Age*Participants)
vif(m9.glm)
```

The interaction between Age and Participants leads to unacceptable collinearity and we thus do not include it in the model. We proceed by adding the interaction between Gender and SituationType.

```{r likeac_4b_048, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Gender*SituationType
m10.glm <- update(m3.glm, .~.+ Gender*SituationType)
vif(m10.glm)
m10.glmer <- update(m3.glmer, .~.+ Gender*SituationType)
anova(m10.glmer, m3.glmer, test = "Chi")     
```

The interaction between Gender and SituationType is not significant and we thus do not retain it in the model. We proceed by adding the interaction between Gender and Like_Freq.

```{r likeac_4b_049, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Gender*Like_Freq
m11.glm <- update(m3.glm, .~.+ Gender*Like_Freq)
vif(m11.glm)
m11.glmer <- update(m3.glmer, .~.+ Gender*Like_Freq)
anova(m11.glmer, m3.glmer, test = "Chi")     
```

The interaction between Gender and Like_Freq is not significant and we thus do not retain it in the model. We proceed by adding the interaction between Gender and Participants.

```{r likeac_4b_050, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Gender*Participants
m12.glm <- update(m3.glm, .~.+ Gender*Participants)
vif(m12.glm)
m12.glmer <- update(m3.glmer, .~.+ Gender*Participants)
anova(m12.glmer, m3.glmer, test = "Chi")       
```

The interaction between Gender and Participants is not significant and we thus do not retain it in the model. We proceed by adding the interaction between SituationType and Like_Freq.

```{r likeac_4b_051, echo=T, eval = T, message=FALSE, warning=FALSE}
# add SituationType*Like_Freq
m13.glm <- update(m3.glm, .~.+ SituationType*Like_Freq)
vif(m13.glm)
m13.glmer <- update(m3.glmer, .~.+ SituationType*Like_Freq)
anova(m13.glmer, m3.glmer, test = "Chi")     
Anova(m13.glmer, type = "III", test = "Chi")   
```

The interaction between SituationType and Like_Freq is significant (on the variable level) and we thus retain it in the model.  We proceed by adding the interaction between SituationType and Participants.

```{r likeac_4b_052, echo=T, eval = T, message=FALSE, warning=FALSE}
# add SituationType*Participants
m14.glm <- update(m13.glm, .~.+ SituationType*Participants)
vif(m14.glm)
m14.glmer <- update(m13.glmer, .~.+ SituationType*Participants)
anova(m14.glmer, m13.glmer, test = "Chi")     
Anova(m14.glmer, type = "III", test = "Chi")   
```

The interaction between SituationType and Participants is not significant (on the variable level) and we thus do not retain it in the model.  We proceed by adding the interaction between Like_Freq and Participants.

```{r likeac_4b_053, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Like_Freq*Participants
m15.glm <- update(m13.glm, .~.+ Like_Freq*Participants)
vif(m15.glm)
m15.glmer <- update(m13.glmer, .~.+ Like_Freq*Participants)
anova(m15.glmer, m13.glmer, test = "Chi")      
```

The interaction between Like_Freq and Participants  is not significant and we thus do not retain it in the model. We have arrived at a minimal adequate model and proceed with model diagnostics and create the diagnostic plots. We have arrived at a minimal adequate model and proceed with model diagnostics and create the diagnostic plots.

```{r likeac_4d_054, echo=T, eval = T, message=FALSE, warning=FALSE}
# start plotting
plot(m13.glmer, pch = 20, col = "black")         
```

We now check if the data contains data points that have an unacceptably high impact on the model by plotting the Cook's distance. To plot Cook's Distance, we create a glm object which also contains Turn as a predictor as it is included in the final glmer model in the random effect structure. This way, the predictions of the glm and the glmar model are identical.

```{r likeac_4d_055, echo=T, eval = T, message=FALSE, warning=FALSE}
m13b.glm <- update(m13.glm, .~.+ Child)
# determine a cutoff for data points that have D-values higher than 4/(n-k-1) 
cutoff <- 4/((nrow(lex)-length(m13b.glm$coefficients)-2))
cutoff
```

The Cook's distance plot names three data points that may cause issues. Also, if we apply the data driven cutoff for Cook's distance (0.001814882), we would retain only 55 data points which is unacceptable. 

We thus have to adapt the cutoff manually and plot the cook's distance values. 

```{r likeac_4d_056, echo=T, eval = T, message=FALSE, warning=FALSE}
# plot cook*s distance
plot(m13b.glm, which=4, cook.levels = cutoff) 
```

There are three 3 data points that are suggested as potential outliers which is why we add influence statistics to our data to get some more information about data points that may require removing.

```{r likeac_4d_057, echo=T, eval = T, message=FALSE, warning=FALSE}
# extract influence statistics
infl <- influence.measures(m13b.glm)       
# add infl. statistics to data
lex <- data.frame(lex, infl[[1]], infl[[2]]) 
```

We now add an index to the data to better identify problematic data points. Then, we order the data by the Cook's distance values and display the data to inlexct the data points with the highest Cook's distance.

```{r likeac_4d_058, echo=T, eval = T, message=FALSE, warning=FALSE}
# create index for data
lex$id <- 1:nrow(lex)
lex <- lex[order(lex$cook.d, decreasing = T),]
head(lex)
```

The diagnostics do not indicate that we have to remove data points as, overall, the Cook's distance is distributed  evenly and we proceed by extracting the model statistics, adding them to the data set, and creating additional model diagnostic plots. 

```{r likeac_4d_059, echo=T, eval = T, message=FALSE, warning=FALSE}
# add diagnostics
lex$residuals <- resid(m13b.glm)
lex$standardized.residuals <- rstandard(m13b.glm)
lex$studentized.residuals <- rstudent(m13b.glm)
lex$cooks.distance <- cooks.distance(m13b.glm)
lex$dffit <- dffits(m13b.glm)
lex$leverage <- hatvalues(m13b.glm)
lex$covariance.ratios <- covratio(m13b.glm)
lex$fitted <- m13b.glm$fitted.values
# plot diagnostics
p1 <- ggplot(lex, 
              aes(studentized.residuals)) +
  theme(legend.position = "none") +
  theme_set(theme_bw(base_size = 8))+ 
  geom_histogram(aes(y=..density..),
                 binwidth = 1,
                 colour="black",
                 fill="white") +
  labs(x = "Studentized Residual", y = "Density") + 
  stat_function(fun = dnorm, 
                args = list(mean = mean(lex$studentized.residuals, na.rm = TRUE), 
                            sd = sd(lex$studentized.residuals, na.rm = TRUE)), 
                colour = "red", size = 1)
p1
```

The diagnostic plots confirms that we will have to remove data points. To identify these points, we plot the fitted values against the studentized residuals.

```{r likeac_4d_060, echo=T, eval = T, message=FALSE, warning=FALSE}
# plot diagnostics
p2 <- ggplot(lex, aes(fitted, studentized.residuals)) +
  geom_point() + 
  geom_smooth(method = "lm", colour = "Red")+
  theme_set(theme_bw(base_size = 8))+ 
  labs(x = "Fitted Values", 
       y = "Studentized Residual")
p2
```

```{r likeac_4d_061, echo=T, eval = T, message=FALSE, warning=FALSE}
# plot diagnostics
p3 <- qplot(sample = lex$studentized.residuals, stat="qq") + 
  theme_set(theme_bw(base_size = 8))+ 
  labs(x = "Theoretical Values", 
       y = "Observed Values")
p3
```

The additional model diagnostic plots do not look perfect. However, we proceed by inspecting the accuracy of the model summarizing the final minimal adequate model.

```{r likeac_4d_062, echo=T, eval = T, message=FALSE, warning=FALSE}
# calculate accuracy
lex$PredictedLexicalIndecisionProbability <- predict(m13.glmer, lex, type="response")
lex$PredictedLexicalIndecisionProbability <- ifelse(lex$PredictedLexicalIndecisionProbability >.5, 1, 0)
# load library
library(caret)
# create confusion matrix
confusionMatrix(as.factor(lex$PredictedLexicalIndecisionProbability), as.factor(lex$LexicalIndecision))
```

The model has a very good accuracy (77.29% accuracy) against a base-line model accuracy of only 65.93% and it performs significantly better than  the  base-line model (p-value = 0.00000171). We call the model summary.

```{r likeac_4d_063, echo=T, eval = T, message=FALSE, warning=FALSE}
# call model summary
summary(m13.glmer)
```

We use the lexorted deviances to calculate the explained variance (nulldeviance-finaldeviance)/(nulldeviance). We also call the baseline model to extract the null deviance.

```{r likeac_4d_064, echo=T, eval = T, message=FALSE, warning=FALSE}
# call model summary
summary(m0.glmer)
```


```{r likeac_4d_119, echo=T, eval = T, message=FALSE, warning=FALSE}
# calculate explained variance
((326.9-310.3)/326.9)*100
```

The model explains 5.078006% more deviance than an intercept-only baseline model. We can now summarize the final minimal adequate model. To do so, we write a summary function for the mixed-effects binomial logistic regression model.

```{r likeac_4d_065, echo=T, eval = T, message=FALSE, warning=FALSE}
# write summary funtion
meblrm.summary <- function(glm0, glm1, glmer0, glmer1, dpvar, data) {
  p.nice <- function(z) {
    as.vector(unlist(sapply(z, function(w) {
      ifelse(w < .001, return("p < .001***"),
      ifelse(w < .01, return("p <  .01 **"),
      ifelse(w < .05, return("p <  .05  *"), 
      ifelse(w < .1, return("p <  .10(*)"), return("n.s."))))) } ))) }
  
  LLglm0 <- logLik(glm0)
  LLglmer0 <- logLik(glmer0)
  LLR01 <- as.vector(- 2 * (LLglm0 - LLglmer0))
  df <- attr(LLglmer0, "df") - attr(LLglm0, "df")
  p <- pchisq(LLR01, df, lower.tail = FALSE)
  headranef <- c("Group(s)", "Variance", "Std. Dev.", " ", "  ", "L.R. X2", "DF", "Pr", "Significance")
  ranef <- c(names(summary(glmer1)[[9]]), round(summary(glmer1)[[13]][[1]][[1]],2), 
  round(as.data.frame(VarCorr(glmer1))[[5]], 2), 
    "", "", round(LLR01, 2), df, round(p, 4), p.nice(p))

# take vif-mer function from https://github.com/aufrank/R-hacks/blob/master/mer-utils.R on 14th August, 2014
vif.mer <- function (fit) {
  ## adapted from rms::vif
  v <- vcov(fit)
  nam <- names(fixef(fit))
  ## exclude intercepts
  ns <- sum(1 * (nam == "Intercept" | nam == "(Intercept)"))
  if (ns > 0) {
  v <- v[-(1:ns), -(1:ns), drop = FALSE]
  nam <- nam[-(1:ns)]
  }
  d <- diag(v)^0.5
  v <- diag(solve(v/(d %o% d)))
  names(v) <- nam
  v
}
kappa.mer <- function (fit, scale = TRUE, center = FALSE,
  add.intercept = TRUE, exact = FALSE) {
  X <- fit@X
  nam <- names(fixef(fit))
  ## exclude intercepts
  nrp <- sum(1 * (nam == "(Intercept)"))
  if (nrp > 0) {
    X <- X[, -(1:nrp), drop = FALSE]
    nam <- nam[-(1:nrp)]
    }
  if (add.intercept) {
    X <- cbind(lex(1), scale(X, scale = scale, center = center))
    kappa(X, exact = exact)
    } else {
    kappa(scale(X, scale = scale, center = scale), exact = exact)
  }
}
colldiag.mer <- function (fit, scale = TRUE, center = FALSE,
  add.intercept = TRUE) {
  ## adapted from perturb::colldiag, method in Belsley, Kuh, and
  ## Welsch (1980). look for a high condition index (> 30) with
  ## more than one high variance propotion. see ?colldiag for more
  ## tips.
  result <- NULL
  if (center)
  add.intercept <- FALSE
  if (is.matrix(fit) || is.data.frame(fit)) {
    X <- as.matrix(fit)
    nms <- colnames(fit)
    }
  else if (class(fit) == "mer") {
    nms <- names(fixef(fit))
    X <- fit@X
      if (any(glexl("(Intercept)", nms))) {
      add.intercept <- FALSE
    }
  }
  X <- X[!is.na(apply(X, 1, all)), ]
  if (add.intercept) {
    X <- cbind(1, X)
    colnames(X)[1] <- "(Intercept)"
    }
  X <- scale(X, scale = scale, center = center)
  svdX <- svd(X)
  svdX$d
  condindx <- max(svdX$d)/svdX$d
  dim(condindx) <- c(length(condindx), 1)
  Phi = svdX$v %*% diag(1/svdX$d)
  Phi <- t(Phi^2)
  pi <- prop.table(Phi, 2)
  colnames(condindx) <- "cond.index"
  if (!is.null(nms)) {
    rownames(condindx) <- nms
    colnames(pi) <- nms
    rownames(pi) <- nms
  } else {
    rownames(condindx) <- 1:length(condindx)
    colnames(pi) <- 1:ncol(pi)
    rownames(pi) <- 1:nrow(pi)
  }
  result <- data.frame(cbind(condindx, pi))
  zapsmall(result)
}
maxcorr.mer <- function (fit, exclude.intercept = TRUE) {
  so <- summary(fit)
  corF <- so@vcov@factors$correlation
  nam <- names(fixef(fit))
  ## exclude intercepts
  ns <- sum(1 * (nam == "Intercept" | nam == "(Intercept)"))
  if (ns > 0 & exclude.intercept) {
    corF <- corF[-(1:ns), -(1:ns), drop = FALSE]
    nam <- nam[-(1:ns)]
  }
  corF[!lower.tri(corF)] <- 0
  maxCor <- max(corF)
  minCor <- min(corF)
  if (abs(maxCor) > abs(minCor)) {
    zapsmall(maxCor)
  } else {
    zapsmall(minCor)
  }
}

# continue with setting up table
  coefs <- summary(glmer1)[[10]]

  se <- sqrt(diag(vcov(glmer1)))
  cilwr <- fixef(glmer1) - 1.96 * se
  ciupr <- fixef(glmer1) + 1.96 * se
  coef.df <- data.frame(
    round(coefs[, 1], 2),
    c("", round(vif.mer(glmer1), 2)),
    round(exp(coefs[, 1]), 2),
    round(exp(cilwr), 2),
    round(exp(ciupr), 2),
    round(coefs[, 2], 2),
    round(coefs[, 3], 2),
    round(coefs[, 4], 4),
    p.nice(coefs[, 4]))
  colnames(coef.df) <- c(colnames(coefs)[1],
    "VIF",
    "OddsRatio",
    "CI(2.5%)",
    "CI(97.5%)",
    colnames(coefs)[2],
    colnames(coefs)[3],
    colnames(coefs)[4],
    "Significance")
    
  coef.df <- rbind(colnames(coef.df), coef.df)
  coef.df <- as.data.frame(coef.df)
  colnames(coef.df) <- c(colnames(coefs)[1],
    "VIF",
    "OddsRatio",
    "CI(2.5%)",
    "CI(97.5%)",
    colnames(coefs)[2],
    colnames(coefs)[3],
    colnames(coefs)[4],
    "Significance")
    
  mdl.statz <- c("", "", "", "", "", "", "", "", "Value")
  groups <- c("", "", "", "", "", "", "", "", summary(glmer1)[[9]][[1]])
  nbcases <- c("", "", "", "", "", "", "", "", length(fitted(glmer1)))
  obs0 <- c("", "", "", "", "", "", "", "", sum(dpvar == 0))
  obs1  <- c("", "", "", "", "", "", "", "", sum(dpvar == 1))
  resdev <- c("", "", "", "", "", "", "", "", round(summary(glmer1)[[3]][[1]][[8]], 2))

  logisticPseudoR2s <- function(glm0, glmer0, glmer1) {
    dev <- deviance(glmer1)
    nullDev <- deviance(glmer0)
    modelN <-  length(fitted(glmer1))
    
    nullDev.glm <- glm0$null.deviance
    R.l.glm <-  1-dev/nullDev.glm
    R.cs.glm <- 1-exp(-(nullDev.glm-dev)/modelN)
    R.n.glm <- R.cs.glm/(1-(exp(-(nullDev.glm/modelN))))
    
    return(c(R.l.glm,      # Hosmer and Lemeshow R^2
      R.cs.glm,            # Cox and Snell R^2
      R.n.glm))            # Nagelkerke R^2
  }

  r2s <- logisticPseudoR2s(glm0, glmer0, glmer1)
  R2Nagelkerke <- c("", "","", "", "", "", "", "",round(r2s[[3]], 3))
  R2HosmerLemeshow <- c("", "","", "", "", "", "", "",round(r2s[[1]], 3))
  R2CoxSnell <- c("", "","", "", "", "", "", "",round(r2s[[2]], 3))

  probs <- predict(glmer1, data, type = "response")
  lexstatz <- somers2(probs, as.numeric(dpvar)-1)

  C <- c("", "", "", "", "", "", "", "",round(lexstatz[[1]], 3))
  Dxy <- c("", "", "", "", "", "", "", "",round(lexstatz[[2]], 3))
  AIC <- c("", "", "", "", "", "", "", "", round(summary(glmer1)[[14]][[1]], 2))
  BIC <- c("", "", "", "", "", "", "", "", round(summary(glmer1)[[14]][[2]], 2))


  dpvarneg <- sapply(dpvar, function(x) ifelse(x == 1, 0, 1))
  correct <- sum(dpvar * (predict(glmer1, type = "response") >= 0.5)) + sum(dpvarneg * (predict(glmer1, type="response") < 0.5))
  tot <- length(dpvar)
  predict.acc <- (correct/tot)*100 

  Accuracy <- c("", "", "", "", "", "", "", "", paste(round(predict.acc, 2), "%", sep = "", collapse = ""))
  
  L0 <- logLik(glm0)
  L1 <- logLik(glmer1)
  L01 <- as.vector(- 2 * (L0 - L1))
  df <- attr(L1, "df") - attr(L0, "df")
    
  ModelLikelihoodRatioTest <- c("", "", "", "", "",
    paste("L.R. X2: ", round(L01, 2), sep = "", collapse = ""),
    paste("DF: ", df, sep = "", collapse = ""),
    paste("p-value: ", round(pchisq(L01, df, lower.tail = FALSE), 5), sep = "", collapse = ""),
    paste("sig: ", p.nice(pchisq(L01, df, lower.tail = FALSE)), sep = "", collapse = ""))

  ranef.tb <- rbind(ranef)
  ranef.df <- as.data.frame(ranef.tb)
  colnames(ranef.df) <- colnames(coef.df)
    
  gblstz.tb <- rbind(mdl.statz, groups, nbcases, obs0, obs1, resdev,
    R2Nagelkerke, R2HosmerLemeshow, R2CoxSnell, C, Dxy, AIC, BIC, Accuracy, ModelLikelihoodRatioTest)
  gblstz.df <- as.data.frame(gblstz.tb)
  colnames(gblstz.df) <- colnames(coef.df)

  blr.tb <- rbind(ranef.df, coef.df, gblstz.df)
  colnames(blr.tb) <- headranef
  rownames(blr.tb) <- c("Random Effect(s)", "Fixed Effect(s)", rownames(coefs),
    "Model statistics", "Number of Groups", "Number of cases in model", 
    "Observed misses", "Observed successes",
    "Residual deviance", "R2 (Nagelkerke)", "R2 (Hosmer & Lemeshow)",
    "R2 (Cox & Snell)", "C", "Somers' Dxy", "AIC", "BIC", "Prediction accuracy", "Model Likelihood Ratio Test")
  blr.df <- as.data.frame(blr.tb)
return(blr.df)
}
```

Now we can apply the summary function to the models that we have created.

```{r likeac_4d_066, echo=T, eval = T, message=FALSE, warning=FALSE}
# set up summary table
mblrm_lex <- meblrm.summary(m0.glm, m13.glm, m0.glmer, m13.glmer, lex$LexicalIndecision, lex) 
# save results to disc
write.table(mblrm_lex, "datatables/mblrm_lex_pp.txt", sep="\t")
mblrm_lex
```

We now save summary of the final minimal adequate model and check other model summaries.

```{r likeac_4d_067, echo=T, eval = T, message=FALSE, warning=FALSE}
# Anova summary
mblrm_lex_Anova <- Anova(m13.glmer, type = "III", test = "Chi")
mblrm_lex_Anova
```

We save this new summary and store the effect sizes of the predictors.

```{r likeac_4d_068, echo=T, eval = T, message=FALSE, warning=FALSE}
# save results to disc
write.table(mblrm_lex_Anova, "datatables/mblrm_lex_Anova_pp.txt", sep="\t")
# extract effect sizes
effectsituationtype <- anova(m0.glmer, m3.glmer, test = "Chi")
effectsituationtypelikefreq <- anova(m3.glmer, m13.glmer, test = "Chi")
effectsituationtype; effectsituationtypelikefreq
```

We now create a data set for plotting the results of the analysis.

```{r likeac_4d_069, echo=T, eval = T, message=FALSE, warning=FALSE}
#names(table(lex$SituationType))
SituationType <- names(table(lex$SituationType))
#summary(lex$Like_Freq)
Like_Freq <- seq(0, 7, .1)
#names(table(lex$Child))
Child <- names(table(lex$Child))
pd <- data.frame(
  rep(Child, each = (length(SituationType)*length(Like_Freq))),
  rep(SituationType, each = length(Child), times = length(Like_Freq)),
  rep(Like_Freq, (length(Child)*length(SituationType))))
colnames(pd) <- c("Child", "SituationType", "Like_Freq")
pd$PredictedLexicalIndecisionProbability <- predict(m13.glmer, pd, type = "response")
pd <- pd %>%
  dplyr::mutate(SituationType = factor(SituationType),
                Child = factor(Child))
# inspect data
head(pd)
```

Plot the effects.

```{r likeac_4d_070, echo=T, eval = T, message=FALSE, warning=FALSE}
p4 <- ggplot(pd, aes(x = Like_Freq, y = PredictedLexicalIndecisionProbability, 
                      group = SituationType, color = SituationType, linetype = SituationType)) +
  geom_smooth(se = F) + 
  guides(color=guide_legend(override.aes=list(fill=NA))) +
  scale_linetype_manual(values=c("dotted", "solid"),
                        name="Situation type",
                        breaks = c("formal", "informal"), 
                        labels = c("formal", "informal")) +
  scale_colour_manual(values=c("grey20",  "grey60"),
                      name="Situation type", 
                      breaks=c("formal", "informal"), 
                      labels = c("formal", "informal")) +
  theme_set(theme_bw(base_size = 15)) +  
  theme(legend.position="top", 
        legend.title = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank()) +
  coord_cartesian(ylim = c(0, 1)) +
  labs(y = "Predicted Probability \n of cognitive uses of \n discourse like") +
    scale_x_continuous(name = "Frequency of discourse like in CDS",
                     breaks = seq(0, 7, 1),
                     labels= seq(0, 7, 1)) +
  ggsave(file = paste(imageDirectory, "PredictedLexicalIndecision.png" , sep="/"), 
       height = 4,  width = 7, dpi = 320)
p4
```

We now inspect the random effects. In a first step, we extract the random effects.

```{r likeac_4d_071, echo=T, eval = T, message=FALSE, warning=FALSE}
randomtb <- ranef(m13.glmer)
rndmchild <- as.vector(unlist(randomtb$`Child`))
child <- as.vector(unlist(rownames(randomtb$`Child`)))
rndmchildtb <- data.frame(child, rndmchild)
colnames(rndmchildtb) <- c("Child", "Intercept")
rndmchildtb <- rndmchildtb[order(rndmchildtb$Intercept, decreasing = T),]
rndmchildtb
```

Now, we visualize the adjustments to the intercept.

```{r likeac_4d_072, echo=T, eval = T, message=FALSE, warning=FALSE}
p6 <- ggplot(rndmchildtb, aes(Child, Intercept)) +
  geom_point(aes(reorder(Child, -Intercept, fun = Intercept), y=Intercept)) +
  coord_cartesian(ylim = c(-1.5, 1.5)) +
  theme_set(theme_bw(base_size = 15)) +
  theme(legend.position="none", 
        axis.text.x = element_text(size=15, angle=90),
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank()) +
  scale_x_discrete(breaks = rndmchildtb$Child[seq(1,length(rndmchildtb$Child),3)]) +
  labs(x = "Child \n(only selected children displayed)", y = "Adjustment to Intercept")
ggsave(file = paste(imageDirectory,"RandomChildLex.png",sep="/"), 
       height = 5,  width = 7.5,  dpi = 320)
# activate (remove #) to show
p6
```

The effect plots from the effects package confirm our customized effect plot and we have thus reached the end of Part 4d of the analysis.
