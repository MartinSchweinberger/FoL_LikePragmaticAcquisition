---
title: "On the L1-acquisition of discourse like - Part 4b"
author: "Anonymous"
date: "`r format(Sys.time(), '%Y-%m-%d')`"
output:
  bookdown::html_document2: default
bibliography: bibliography.bib
link-citations: yes
---

This document shows an analysis that was performed with the aim of investigating the acquiasition of discourse *like* with specifying function in American English based on data from the *Child Language Data Exchange System* (CHILDES). The following represents part 4b of this analysis.

In a first step, we prepare the session by cleaning the workspace, loading packages, setting options, and defining paths.

```{r likeac_4b_001, echo=T, eval = T, message=FALSE, warning=FALSE}
# clean workspace
rm(list=ls(all=T))
# load packages
library(dplyr)
# set options
options(stringsAsFactors = F)
# define image directory
imageDirectory<-"images"
```

Now, we read in the data.

```{r likeac_4b_002, echo=T, eval = T, message=FALSE, warning=FALSE}
# read in data
spe <- read.delim("datatables/spe.txt", sep = "\t", 
                   header=TRUE, quote = "", skipNul = T)
# factorize variables
fctrs <- c("Child", "Gender", "Participants", "Specification", "SituationType")
spe[fctrs] <- lapply(spe[fctrs], factor)
# create boruta data set
borutaspe <- spe
# inspect data
head(spe)
```

We can now begin with the statistical analysis of discourse *like* with specifying function. In a first step, we perform a Boruta analysis as a variable selection procedure to check which variables have any type of meaningful relationship with the use of discourse *like* with speifying function.

```{r likeac_4b_003, echo=T, eval = T, message=FALSE, warning=FALSE}
# load library
library(Boruta)
# run 1
boruta.spe <- Boruta(Specification ~.,data=borutaspe)
print(boruta.spe)
```

We remove variables that are confirmed as being unimportant and rerun the analysis.

```{r likeac_4b_004, echo=T, eval = T, message=FALSE, warning=FALSE}
borutaspe <- borutaspe %>%
  dplyr::select(-Spe_Freq)
# run 2
boruta.spe <- Boruta(Specification ~.,data=borutaspe)
print(boruta.spe)
```

We can visualize the results of the Boruta analysis.

```{r likeac_4b_005, echo=T, eval = T, message=FALSE, warning=FALSE}
plot(boruta.spe)
```

We can now proceed with the regression analysis.

```{r likeac_4b_006, echo=T, eval = T, message=FALSE, warning=FALSE}
# load packages
library(lme4)
library(car)
library(rms)
# set options
options(contrasts  =c("contr.treatment", "contr.poly"))
data.dist <- datadist(spe)
options(datadist = "data.dist")
# create base glm line model
m0.glm = glm(Specification ~ 1, data = spe, family = binomial)
# create base glmm line model
m0.glmer = glmer(Specification ~ (1|Child), data = spe, family = binomial, 
                  control=glmerControl(optimizer="bobyqa"))
# compare AICs
aic.glmer<- AIC(logLik(m0.glmer))
aic.glm <- AIC(logLik(m0.glm))
aic.glmer; aic.glm
```

```{r likeac_4b_007, echo=T, eval = T, message=FALSE, warning=FALSE}
# test random effects
null.id = -2 * logLik(m0.glm) + 2 * logLik(m0.glmer)
pchisq(as.numeric(null.id), df=1, lower.tail=F) 
```

The glmm has a significantly better model fit compared to the glm model. We now check if Age is a significant predictor for speifying uses of discourse *like*.

```{r likeac_4b_008, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Age
m1.glm <- update(m0.glm, .~.+Age)
m1.glmer <- update(m0.glmer, .~.+Age)
anova(m1.glmer, m0.glmer, test = "Chi")     
Anova(m1.glmer, type = "III", test = "Chi")   
```

As Age is significant, we retain it in the model and proceed by adding Gender.

```{r likeac_4b_009, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Gender
ifelse(min(ftable(spe$Gender, spe$Specification)) == 0, "not possible", "possible")
m2.glm <- update(m1.glm, .~.+Gender)
vif(m2.glm)
m2.glmer <- update(m1.glmer, .~.+Gender)
anova(m2.glmer, m1.glmer, test = "Chi")     
Anova(m2.glmer, type = "III", test = "Chi")   
```

As Gender is not significant, we do not retain it in the model and proceed by adding SituationType.

```{r likeac_4b_010, echo=T, eval = T, message=FALSE, warning=FALSE}
# add SituationType
ifelse(min(ftable(spe$SituationType, spe$Specification)) == 0, "not possible", "possible")
m3.glm <- update(m1.glm, .~.+SituationType)
vif(m3.glm)
m3.glmer <- update(m1.glmer, .~.+SituationType)
anova(m3.glmer, m1.glmer, test = "Chi")     
Anova(m3.glmer, type = "III", test = "Chi")   
```

As SituationType is significant, we retain it in the model and proceed by adding Like_Freq.

```{r likeac_4b_011, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Like_Freq
m4.glm <- update(m3.glm, .~.+Like_Freq)
vif(m4.glm)
m4.glmer <- update(m3.glmer, .~.+Like_Freq)
anova(m4.glmer, m3.glmer, test = "Chi")     
Anova(m4.glmer, type = "III", test = "Chi")   
```

As Like_Freq is not significant, we do not retain it in the model and proceed by adding Participants.

```{r likeac_4b_012, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Participants
m5.glm <- update(m3.glm, .~.+ Participants)
vif(m5.glm)
m5.glmer <- update(m3.glmer, .~.+ Participants)
anova(m5.glmer, m3.glmer, test = "Chi")     
Anova(m5.glmer, type = "III", test = "Chi")   
```

As Participants is not significant, we do not retain it in the model and proceed by adding all secondary or two-way interactions. We begin by adding Age*Gender.

```{r likeac_4b_013, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Age*Gender
m6.glm <- update(m3.glm, .~.+ Age*Gender)
vif(m6.glm)
m6.glmer <- update(m3.glmer, .~.+ Age*Gender)
anova(m6.glmer, m3.glmer, test = "Chi")     
Anova(m6.glmer, type = "III", test = "Chi")   
```

As the interaction between Age and Gender is not significant, we do not retain it in the model and proceed by adding the interaction between Age and SituationType.

```{r likeac_4b_014, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Age*SituationType
m7.glm <- update(m3.glm, .~.+ Age*SituationType)
vif(m7.glm)
```

Adding the interaction between Age and SituationType leads to unacceptable collinearity and we thus do not include it in the model. We proceed by adding the interaction between Age and Like_Freq.

```{r likeac_4b_015, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Age*Like_Freq
m8.glm <- update(m3.glm, .~.+ Age*Like_Freq)
vif(m8.glm)
m8.glmer <- update(m3.glmer, .~.+ Age*Like_Freq)
anova(m8.glmer, m3.glmer, test = "Chi")     
Anova(m8.glmer, type = "III", test = "Chi")   
```

The interaction between Age and Like_Freq is not significant and we thus do not retain it in the model. We proceed by adding the interaction between Age and Participants.

```{r likeac_4b_016, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Age*Participants
m9.glm <- update(m3.glm, .~.+ Age*Participants)
vif(m9.glm)
```

The interaction between Age and Participants leads to unacceptable collinearity and we thus do not include it in the model. We proceed by adding the interaction between Gender and SituationType.

```{r likeac_4b_017, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Gender*SituationType
m10.glm <- update(m3.glm, .~.+ Gender*SituationType)
vif(m10.glm)
m10.glmer <- update(m3.glmer, .~.+ Gender*SituationType)
anova(m10.glmer, m3.glmer, test = "Chi")     
Anova(m10.glmer, type = "III", test = "Chi")   
```

The interaction between Gender and SituationType is not significant and we thus do not retain it in the model. We proceed by adding the interaction between Gender and Like_Freq.

```{r likeac_4b_018, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Gender*Like_Freq
m11.glm <- update(m3.glm, .~.+ Gender*Like_Freq)
vif(m11.glm)
m11.glmer <- update(m3.glmer, .~.+ Gender*Like_Freq)
anova(m11.glmer, m3.glmer, test = "Chi")     
Anova(m11.glmer, type = "III", test = "Chi")   
```

The interaction between Gender and Like_Freq is not significant and we thus do not retain it in the model. We proceed by adding the interaction between Gender and Participants.

```{r likeac_4b_019, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Gender*Participants
m12.glm <- update(m3.glm, .~.+ Gender*Participants)
vif(m12.glm)
m12.glmer <- update(m3.glmer, .~.+ Gender*Participants)
anova(m12.glmer, m3.glmer, test = "Chi")     
Anova(m12.glmer, type = "III", test = "Chi")   
```

The interaction between Gender and Participants is not significant and we thus do not retain it in the model. We proceed by adding the interaction between SituationType and Like_Freq.

```{r likeac_4b_020, echo=T, eval = T, message=FALSE, warning=FALSE}
# add SituationType*Like_Freq
m13.glm <- update(m3.glm, .~.+ SituationType*Like_Freq)
vif(m13.glm)
m13.glmer <- update(m3.glmer, .~.+ SituationType*Like_Freq)
anova(m13.glmer, m3.glmer, test = "Chi")     
Anova(m13.glmer, type = "III", test = "Chi")   
```

The interaction between SituationType and Like_Freq is not significant and we thus do not retain it in the model.  We proceed by adding the interaction between SituationType and Participants.

```{r likeac_4b_021, echo=T, eval = T, message=FALSE, warning=FALSE}
# add SituationType*Participants
m14.glm <- update(m3.glm, .~.+ SituationType*Participants)
vif(m14.glm)
m14.glmer <- update(m3.glmer, .~.+ SituationType*Participants)
anova(m14.glmer, m3.glmer, test = "Chi")     
Anova(m14.glmer, type = "III", test = "Chi")   
```

The interaction between SituationType and Participants  is not significant and we thus do not retain it in the model.  We proceed by adding the interaction between Like_Freq and Participants.

```{r likeac_4b_022, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Like_Freq*Participants
m15.glm <- update(m3.glm, .~.+ Like_Freq*Participants)
vif(m15.glm)
m15.glmer <- update(m3.glmer, .~.+ Like_Freq*Participants)
anova(m15.glmer, m3.glmer, test = "Chi")     
Anova(m15.glmer, type = "III", test = "Chi")   
```

The interaction between Like_Freq and Participants  is not significant and we thus do not retain it in the model. We have arrived at a minimal adequate model and proceed with model diagnostics and create the diagnostic plots.

```{r likeac_4b_023, echo=T, eval = T, message=FALSE, warning=FALSE}
# start plotting
plot(m3.glmer, pch = 20, col = "black")         
```

We now check if the data contains data points that have an unacceptably high impact on the model by plotting the Cook's distance. To plot Cook's Distance, we create a glm object which also contains Turn as a predictor as it is included in the final glmer model in the random effect structure. This way, the predictions of the glm and the glmar model are identical.

```{r likeac_4b_024, echo=T, eval = T, message=FALSE, warning=FALSE}
m3b.glm <- update(m3.glm, .~.+ Child)
# determine a cutoff for data points that have D-values higher than 4/(n-k-1) 
cutoff <- 4/((nrow(spe)-length(m3b.glm$coefficients)-2))
cutoff
```

The Cook's distance plot names three data points that may cause issues. Also, if we apply the data driven cutoff for Cook's distance (0.001814882), we would retain only 55 data points which is unacceptable. 

We thus have to adapt the cutoff manually and plot the cook's distance values. 

```{r likeac_4b_025, echo=T, eval = T, message=FALSE, warning=FALSE}
# plot cook*s distance
plot(m3b.glm, which=4, cook.levels = cutoff) 
```

There are three 3 data points that are suggested as potential outlierswhich is why we add influence statistics to our data to get some more information about data points that may require removing.

```{r likeac_4b_026, echo=T, eval = T, message=FALSE, warning=FALSE}
# extract influence statistics
infl <- influence.measures(m3b.glm)       
# add infl. statistics to data
spe <- data.frame(spe, infl[[1]], infl[[2]]) 
```

We now add an index to the data to better identify problematic data points. Then, we order the data by the Cook's distance values and display the data to inspect the data points with the highest Cook's distance.

```{r likeac_4b_027, echo=T, eval = T, message=FALSE, warning=FALSE}
# create index for data
spe$id <- 1:nrow(spe)
spe <- spe[order(spe$cook.d, decreasing = T),]
head(spe)
```

The diagnostics do not indicate that we have to remove data points as, overall, the Cook's distance is distributed  evenly and we proceed by extracting the model statistics, adding them to the data set, and creating additional model diagnostic plots. 

```{r likeac_4b_028, echo=T, eval = T, message=FALSE, warning=FALSE}
# add diagnostics
spe$residuals <- resid(m3b.glm)
spe$standardized.residuals <- rstandard(m3b.glm)
spe$studentized.residuals <- rstudent(m3b.glm)
spe$cooks.distance <- cooks.distance(m3b.glm)
spe$dffit <- dffits(m3b.glm)
spe$leverage <- hatvalues(m3b.glm)
spe$covariance.ratios <- covratio(m3b.glm)
spe$fitted <- m3b.glm$fitted.values
# plot diagnostics
p1 <- ggplot(spe, 
              aes(studentized.residuals)) +
  theme(legend.position = "none") +
  theme_set(theme_bw(base_size = 8))+ 
  geom_histogram(aes(y=..density..),
                 binwidth = 1,
                 colour="black",
                 fill="white") +
  labs(x = "Studentized Residual", y = "Density") + 
  stat_function(fun = dnorm, 
                args = list(mean = mean(spe$studentized.residuals, na.rm = TRUE), 
                            sd = sd(spe$studentized.residuals, na.rm = TRUE)), 
                colour = "red", size = 1)
p1
```

The diagnostic plots confirms that we will have to remove data points. To identify these points, we plot the fitted values against the studentized residuals.

```{r likeac_4b_029, echo=T, eval = T, message=FALSE, warning=FALSE}
# plot diagnostics
p2 <- ggplot(spe, aes(fitted, studentized.residuals)) +
  geom_point() + 
  geom_smooth(method = "lm", colour = "Red")+
  theme_set(theme_bw(base_size = 8))+ 
  labs(x = "Fitted Values", 
       y = "Studentized Residual")
p2
```

```{r likeac_4b_030, echo=T, eval = T, message=FALSE, warning=FALSE}
# plot diagnostics
p3 <- qplot(sample = spe$studentized.residuals, stat="qq") + 
  theme_set(theme_bw(base_size = 8))+ 
  labs(x = "Theoretical Values", 
       y = "Observed Values")
p3
```

```{r likeac_4b_031, echo=T, eval = T, message=FALSE, warning=FALSE}
spe <- spe %>%
  dplyr::arrange(studentized.residuals)
# inspect reordered data
spe[1:10, c(ncol(spe)-5:ncol(spe))]; spe[c(nrow(spe)-5:nrow(spe)), c(ncol(spe)-5:ncol(spe))]
```

We have now identified the problematic data points which are the points that have the IDs 308, 272, 376, 11, 115, 305, 224, 345 and 159. We remove these points as well as the diagnostic values and repeat the analysis.

```{r likeac_4b_032, echo=T, eval = T, message=FALSE, warning=FALSE}
rmv <- c(308, 272, 376, 11, 115, 305, 224, 345, 159)
# define not in
`%notin%` <- Negate(`%in%`)
spe <- spe %>%
  dplyr::filter(id %notin% rmv) %>%
  # remove diagnostic statistics
  dplyr::select(-dfb.1_, -dfb.Age, -dfb.SttT, -dfb.Childl, -dfb.Chldll,
                -dfb.Chldnn, -dfb.Childst, -dfb.Chldbb, -dfb.Childbra,
                -dfb.Childbri, -dfb.Chldbrn, -dfb.Chldcs, -dfb.Chldcl,
                -dfb.Chldcn, -dfb.Chldct, -dfb.Childdav, -dfb.Childdev,
                -dfb.Childd, -dfb.Chldth, -dfb.Childg, -dfb.Chldgr, 
                -dfb.Childn, -dfb.Chldjc, -dfb.Chldjm, -dfb.Childje,
                -dfb.Chldjb, -dfb.Chldjn, -dfb.Chldjr, -dfb.Childjes,
                -dfb.Childjo, -dfb.Chldjy, -dfb.Childjus, -dfb.Childkar,
                -dfb.Chldkv, -dfb.Childkur, -dfb.Childmr, -dfb.Chldmy,
                -dfb.Chldmg, -dfb.Chldml, -dfb.Chldmn, -dfb.Chldmrk,
                -dfb.Childp, -dfb.Chldpt, -dfb.Childras, -dfb.Chldrm,
                -dfb.Chldrl, -dfb.Chldrc, -dfb.Childros, -dfb.Chldsr,
                -dfb.Chldstn, -dfb.Chldss, -dfb.Chldtd, -dfb.Chldtm,
                -dfb.Chldtr, -dfb.Chldv, -dfb.Chldz, -dffit, -cov.r, 
                -cook.d, -hat, -dfb.1_.1, -dfb.Age.1, -dfb.SttT.1,
                -dfb.Childl.1, -dfb.Chldll.1, -dfb.Chldnn.1, -dfb.Childst.1,
                -dfb.Chldbb.1, -dfb.Childbra.1, -dfb.Childbri.1, -dfb.Chldbrn.1,
                -dfb.Chldcs.1, -dfb.Chldcl.1, -dfb.Chldcn.1, -dfb.Chldct.1,
                -dfb.Childdav.1, -dfb.Childdev.1, -dfb.Childd.1, 
                -dfb.Chldth.1, -dfb.Childg.1, -dfb.Chldgr.1, -dfb.Childn.1,
                -dfb.Chldjc.1, -dfb.Chldjm.1, -dfb.Childje.1, -dfb.Chldjb.1,
                -dfb.Chldjn.1, -dfb.Chldjr.1, -dfb.Childjes.1, -dfb.Childjo.1,
                -dfb.Chldjy.1, -dfb.Childjus.1, -dfb.Childkar.1, -dfb.Chldkv.1,
                -dfb.Childkur.1, -dfb.Childmr.1, -dfb.Chldmy.1, -dfb.Chldmg.1,
                -dfb.Chldml.1, -dfb.Chldmn.1, -dfb.Chldmrk.1, -dfb.Childp.1,
                -dfb.Chldpt.1, -dfb.Childras.1, -dfb.Chldrm.1, -dfb.Chldrl.1,
                -dfb.Chldrc.1, -dfb.Childros.1, -dfb.Chldsr.1, -dfb.Chldstn.1,
                -dfb.Chldss.1, -dfb.Chldtd.1, -dfb.Chldtm.1, -dfb.Chldtr.1,
                -dfb.Chldv.1, -dfb.Chldz.1, -dffit.1, -cov.r.1, -cook.d.1,
                -hat.1, -id, -residuals, -standardized.residuals,
                -studentized.residuals, -cooks.distance, -leverage,
                -covariance.ratios, -fitted)
```

We now repeat the analysis and begin by creating another boruta data set.

```{r likeac_4b_033, echo=T, eval = T, message=FALSE, warning=FALSE}
# create boruta data set
borutaspe <- spe
# inspect data
head(spe)
```

We can now begin with the statistical analysis of discourse *like* with speifying function. In a first step, we perform a Boruta analysis as a variable selection procedure to check which variables have any type of meaningful relationship with the use of discourse *like* with speifying function.

```{r likeac_4b_034, echo=T, eval = T, message=FALSE, warning=FALSE}
# load library
library(Boruta)
# run 1
boruta.spe <- Boruta(Specification ~.,data=borutaspe)
print(boruta.spe)
```

We remove variables that are confirmed as being unimportant and rerun the analysis.

```{r likeac_4b_035, echo=T, eval = T, message=FALSE, warning=FALSE}
borutaspe <- borutaspe %>%
  dplyr::select(-Spe_Freq)
# run 2
boruta.spe <- Boruta(Specification ~.,data=borutaspe)
print(boruta.spe)
```

We can visualize the results of the Boruta analysis.

```{r likeac_4b_036, echo=T, eval = T, message=FALSE, warning=FALSE}
plot(boruta.spe)
```

We can now proceed with the regression analysis.

```{r likeac_4b_037, echo=T, eval = T, message=FALSE, warning=FALSE}
# set options
options(contrasts  =c("contr.treatment", "contr.poly"))
data.dist <- datadist(spe)
options(datadist = "data.dist")
# create base glm line model
m0.glm = glm(Specification ~ 1, data = spe, family = binomial)
# create base glmm line model
m0.glmer = glmer(Specification ~ (1|Child), data = spe, family = binomial, 
                  control=glmerControl(optimizer="bobyqa"))
# compare AICs
aic.glmer<- AIC(logLik(m0.glmer))
aic.glm <- AIC(logLik(m0.glm))
aic.glmer; aic.glm
```

```{r likeac_4b_038, echo=T, eval = T, message=FALSE, warning=FALSE}
# test random effects
null.id = -2 * logLik(m0.glm) + 2 * logLik(m0.glmer)
pchisq(as.numeric(null.id), df=1, lower.tail=F) 
```

The glmm has a significantly better model fit compared to the glm model. We now check if Age is a significant predictor for speifying uses of discourse *like*.

```{r likeac_4b_039, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Age
m1.glm <- update(m0.glm, .~.+Age)
m1.glmer <- update(m0.glmer, .~.+Age)
anova(m1.glmer, m0.glmer, test = "Chi")     
Anova(m1.glmer, type = "III", test = "Chi")   
```

As Age is significant, we retain it in the model and proceed by adding Gender.

```{r likeac_4b_040, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Gender
ifelse(min(ftable(spe$Gender, spe$Specification)) == 0, "not possible", "possible")
m2.glm <- update(m1.glm, .~.+Gender)
vif(m2.glm)
m2.glmer <- update(m1.glmer, .~.+Gender)
anova(m2.glmer, m1.glmer, test = "Chi")     
Anova(m2.glmer, type = "III", test = "Chi")   
```

As Gender is not significant, we do not retain it in the model and proceed by adding SituationType.

```{r likeac_4b_041, echo=T, eval = T, message=FALSE, warning=FALSE}
# add SituationType
ifelse(min(ftable(spe$SituationType, spe$Specification)) == 0, "not possible", "possible")
m3.glm <- update(m1.glm, .~.+SituationType)
vif(m3.glm)
m3.glmer <- update(m1.glmer, .~.+SituationType)
anova(m3.glmer, m1.glmer, test = "Chi")     
Anova(m3.glmer, type = "III", test = "Chi")   
```

As SituationType is significant, we retain it in the model and proceed by adding Like_Freq.

```{r likeac_4b_042, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Like_Freq
m4.glm <- update(m3.glm, .~.+Like_Freq)
vif(m4.glm)
m4.glmer <- update(m3.glmer, .~.+Like_Freq)
anova(m4.glmer, m3.glmer, test = "Chi")     
Anova(m4.glmer, type = "III", test = "Chi")   
```

As Like_Freq is significant, we retain it in the model and proceed by adding Participants.

```{r likeac_4b_043, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Participants
m5.glm <- update(m4.glm, .~.+ Participants)
vif(m5.glm)
m5.glmer <- update(m4.glmer, .~.+ Participants)
anova(m5.glmer, m4.glmer, test = "Chi")     
Anova(m5.glmer, type = "III", test = "Chi")   
```

As Participants is not significant, we do not retain it in the model and proceed by adding all secondary or two-way interactions. We begin by adding Age*Gender.

```{r likeac_4b_044, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Age*Gender
m6.glm <- update(m4.glm, .~.+ Age*Gender)
vif(m6.glm)
m6.glmer <- update(m4.glmer, .~.+ Age*Gender)
anova(m6.glmer, m4.glmer, test = "Chi")     
Anova(m6.glmer, type = "III", test = "Chi")   
```

As the interaction between Age and Gender is not significant, we do not retain it in the model and proceed by adding the interaction between Age and SituationType.

```{r likeac_4b_045, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Age*SituationType
m7.glm <- update(m4.glm, .~.+ Age*SituationType)
vif(m7.glm)
```

Adding the interaction between Age and SituationType leads to unacceptable collinearity and we thus do not include it in the model. We proceed by adding the interaction between Age and Like_Freq.

```{r likeac_4b_046, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Age*Like_Freq
m8.glm <- update(m4.glm, .~.+ Age*Like_Freq)
vif(m8.glm)
m8.glmer <- update(m4.glmer, .~.+ Age*Like_Freq)
anova(m8.glmer, m4.glmer, test = "Chi")     
Anova(m8.glmer, type = "III", test = "Chi")   
```

The interaction between Age and Like_Freq is not significant and we thus do not retain it in the model. We proceed by adding the interaction between Age and Participants.

```{r likeac_4b_047, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Age*Participants
m9.glm <- update(m4.glm, .~.+ Age*Participants)
vif(m9.glm)
```

The interaction between Age and Participants leads to unacceptable collinearity and we thus do not include it in the model. We proceed by adding the interaction between Gender and SituationType.

```{r likeac_4b_048, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Gender*SituationType
m10.glm <- update(m4.glm, .~.+ Gender*SituationType)
vif(m10.glm)
m10.glmer <- update(m4.glmer, .~.+ Gender*SituationType)
anova(m10.glmer, m4.glmer, test = "Chi")     
Anova(m10.glmer, type = "III", test = "Chi")   
```

The interaction between Gender and SituationType is not significant and we thus do not retain it in the model. We proceed by adding the interaction between Gender and Like_Freq.

```{r likeac_4b_049, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Gender*Like_Freq
m11.glm <- update(m4.glm, .~.+ Gender*Like_Freq)
vif(m11.glm)
m11.glmer <- update(m4.glmer, .~.+ Gender*Like_Freq)
anova(m11.glmer, m4.glmer, test = "Chi")       
```

The interaction between Gender and Like_Freq is not significant and we thus do not retain it in the model. We proceed by adding the interaction between Gender and Participants.

```{r likeac_4b_050, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Gender*Participants
m12.glm <- update(m4.glm, .~.+ Gender*Participants)
vif(m12.glm)
```

The interaction between Gender and Participants leads to unacceptable collinearity and we thus do not include it in the model. We proceed by adding the interaction between SituationType and Like_Freq.

```{r likeac_4b_051, echo=T, eval = T, message=FALSE, warning=FALSE}
# add SituationType*Like_Freq
m13.glm <- update(m4.glm, .~.+ SituationType*Like_Freq)
vif(m13.glm)
m13.glmer <- update(m4.glmer, .~.+ SituationType*Like_Freq)
anova(m13.glmer, m4.glmer, test = "Chi")       
```

The interaction between SituationType and Like_Freq is not significant and we thus do not retain it in the model.  We proceed by adding the interaction between SituationType and Participants.

```{r likeac_4b_052, echo=T, eval = T, message=FALSE, warning=FALSE}
# add SituationType*Participants
m14.glm <- update(m4.glm, .~.+ SituationType*Participants)
vif(m14.glm)
m14.glmer <- update(m4.glmer, .~.+ SituationType*Participants)
anova(m14.glmer, m4.glmer, test = "Chi")      
```

The interaction between SituationType and Participants  is not significant and we thus do not retain it in the model.  We proceed by adding the interaction between Like_Freq and Participants.

```{r likeac_4b_053, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Like_Freq*Participants
m15.glm <- update(m5.glm, .~.+ Like_Freq*Participants)
vif(m15.glm)
m15.glmer <- update(m5.glmer, .~.+ Like_Freq*Participants)
anova(m15.glmer, m5.glmer, test = "Chi")     
Anova(m15.glmer, type = "III", test = "Chi")   
```

The interaction between Like_Freq and Participants  is not significant and we thus do not retain it in the model. We have arrived at a minimal adequate model and proceed with model diagnostics and create the diagnostic plots.

```{r likeac_4b_054, echo=T, eval = T, message=FALSE, warning=FALSE}
# start plotting
plot(m4.glmer, pch = 20, col = "black")         
```

We now check if the data contains data points that have an unacceptably high impact on the model by plotting the Cook's distance. To plot Cook's Distance, we create a glm object which also contains Turn as a predictor as it is included in the final glmer model in the random effect structure. This way, the predictions of the glm and the glmar model are identical.

```{r likeac_4b_055, echo=T, eval = T, message=FALSE, warning=FALSE}
m4b.glm <- update(m4.glm, .~.+ Child)
# determine a cutoff for data points that have D-values higher than 4/(n-k-1) 
cutoff <- 4/((nrow(spe)-length(m4b.glm$coefficients)-2))
cutoff
```

The Cook's distance plot names three data points that may cause issues. Also, if we apply the data driven cutoff for Cook's distance (0.001814882), we would retain only 55 data points which is unacceptable. 

We thus have to adapt the cutoff manually and plot the cook's distance values. 

```{r likeac_4b_056, echo=T, eval = T, message=FALSE, warning=FALSE}
# plot cook*s distance
plot(m4b.glm, which=4, cook.levels = cutoff) 
```

There are three 3 data points that are suggested as potential outlierswhich is why we add influence statistics to our data to get some more information about data points that may require removing.

```{r likeac_4b_057, echo=T, eval = T, message=FALSE, warning=FALSE}
# extract influence statistics
infl <- influence.measures(m4b.glm)       
# add infl. statistics to data
spe <- data.frame(spe, infl[[1]], infl[[2]]) 
```

We now add an index to the data to better identify problematic data points. Then, we order the data by the Cook's distance values and display the data to inspect the data points with the highest Cook's distance.

```{r likeac_4b_058, echo=T, eval = T, message=FALSE, warning=FALSE}
# create index for data
spe$id <- 1:nrow(spe)
spe <- spe[order(spe$cook.d, decreasing = T),]
head(spe)
```

The diagnostics do not indicate that we have to remove data points as, overall, the Cook's distance is distributed  evenly and we proceed by extracting the model statistics, adding them to the data set, and creating additional model diagnostic plots. 

```{r likeac_4b_059, echo=T, eval = T, message=FALSE, warning=FALSE}
# add diagnostics
spe$residuals <- resid(m4b.glm)
spe$standardized.residuals <- rstandard(m4b.glm)
spe$studentized.residuals <- rstudent(m4b.glm)
spe$cooks.distance <- cooks.distance(m4b.glm)
spe$dffit <- dffits(m4b.glm)
spe$leverage <- hatvalues(m4b.glm)
spe$covariance.ratios <- covratio(m4b.glm)
spe$fitted <- m4b.glm$fitted.values
# plot diagnostics
p1 <- ggplot(spe, 
              aes(studentized.residuals)) +
  theme(legend.position = "none") +
  theme_set(theme_bw(base_size = 8))+ 
  geom_histogram(aes(y=..density..),
                 binwidth = 1,
                 colour="black",
                 fill="white") +
  labs(x = "Studentized Residual", y = "Density") + 
  stat_function(fun = dnorm, 
                args = list(mean = mean(spe$studentized.residuals, na.rm = TRUE), 
                            sd = sd(spe$studentized.residuals, na.rm = TRUE)), 
                colour = "red", size = 1)
p1
```

The diagnostic plots confirms that we will have to remove data points. To identify these points, we plot the fitted values against the studentized residuals.

```{r likeac_4b_060, echo=T, eval = T, message=FALSE, warning=FALSE}
# plot diagnostics
p2 <- ggplot(spe, aes(fitted, studentized.residuals)) +
  geom_point() + 
  geom_smooth(method = "lm", colour = "Red")+
  theme_set(theme_bw(base_size = 8))+ 
  labs(x = "Fitted Values", 
       y = "Studentized Residual")
p2
```

```{r likeac_4b_061, echo=T, eval = T, message=FALSE, warning=FALSE}
# plot diagnostics
p3 <- qplot(sample = spe$studentized.residuals, stat="qq") + 
  theme_set(theme_bw(base_size = 8))+ 
  labs(x = "Theoretical Values", 
       y = "Observed Values")
p3
```

Now, we identify the data points that are identified as being problematic.

```{r likeac_4b_062, echo=T, eval = T, message=FALSE, warning=FALSE}
spe <- spe %>%
  dplyr::arrange(studentized.residuals)
# inspect data
spe[1:5,c(ncol(spe)-5:ncol(spe))]; spe[c(nrow(spe)-5:nrow(spe)), c(ncol(spe)-5:ncol(spe))]; nrow(spe)
```

We have now identified the problematic data points which are the points that have the IDs 35 as well as 251,18, 365, 283, 212, 123, 121, and 354. We remove these points as well as the diagnostic values and repeat the analysis.

```{r likeac_4b_063, echo=T, eval = T, message=FALSE, warning=FALSE}
rmv <- c(35, 251,18, 365, 283, 212, 123, 121, 354)
# define not in
`%notin%` <- Negate(`%in%`)
spe <- spe %>%
  dplyr::filter(id %notin% rmv) %>%
  # remove diagnostic statistics
  dplyr::select(-dfb.1_, -dfb.Age, -dfb.SttT, -dfb.Lk_F, -dfb.Childl,
                -dfb.Chldll, -dfb.Chldnn, -dfb.Childst, -dfb.Chldbb,
                -dfb.Childbra, -dfb.Childbri, -dfb.Chldbrn, -dfb.Chldcs,
                -dfb.Chldcl, -dfb.Chldcn, -dfb.Chldct, -dfb.Childdav,
                -dfb.Childdev, -dfb.Childd, -dfb.Chldth, -dfb.Childg,
                -dfb.Chldgr, -dfb.Childn, -dfb.Chldjc, -dfb.Chldjm,
                -dfb.Childje, -dfb.Chldjb, -dfb.Chldjn, -dfb.Chldjr,
                -dfb.Childjes, -dfb.Childjo, -dfb.Chldjy, -dfb.Childjus,
                -dfb.Childkar, -dfb.Chldkv, -dfb.Childkur, -dfb.Childmr,
                -dfb.Chldmy, -dfb.Chldmg, -dfb.Chldml, -dfb.Chldmn,
                -dfb.Chldmrk, -dfb.Childp, -dfb.Chldpt, -dfb.Childras,
                -dfb.Chldrm, -dfb.Chldrl, -dfb.Chldrc, -dfb.Childros,
                -dfb.Chldsr, -dfb.Chldstn, -dfb.Chldss, -dfb.Chldtd,
                -dfb.Chldtm, -dfb.Chldtr, -dfb.Chldv, -dfb.Chldz, -dffit,
                -cov.r, -cook.d, -hat, -dfb.1_.1, -dfb.Age.1, -dfb.SttT.1,
                -dfb.Lk_F.1, -dfb.Childl.1, -dfb.Chldll.1, -dfb.Chldnn.1,
                -dfb.Childst.1, -dfb.Chldbb.1, -dfb.Childbra.1, 
                -dfb.Childbri.1, -dfb.Chldbrn.1, -dfb.Chldcs.1, -dfb.Chldcl.1,
                -dfb.Chldcn.1, -dfb.Chldct.1, -dfb.Childdav.1, -dfb.Childdev.1,
                -dfb.Childd.1, -dfb.Chldth.1, -dfb.Childg.1, -dfb.Chldgr.1,
                -dfb.Childn.1, -dfb.Chldjc.1, -dfb.Chldjm.1, -dfb.Childje.1,
                -dfb.Chldjb.1, -dfb.Chldjn.1, -dfb.Chldjr.1, -dfb.Childjes.1,
                -dfb.Childjo.1, -dfb.Chldjy.1, -dfb.Childjus.1, 
                -dfb.Childkar.1, -dfb.Chldkv.1, -dfb.Childkur.1, 
                -dfb.Childmr.1, -dfb.Chldmy.1, -dfb.Chldmg.1, -dfb.Chldml.1,
                -dfb.Chldmn.1, -dfb.Chldmrk.1, -dfb.Childp.1, -dfb.Chldpt.1,
                -dfb.Childras.1, -dfb.Chldrm.1, -dfb.Chldrl.1, -dfb.Chldrc.1,
                -dfb.Childros.1, -dfb.Chldsr.1, -dfb.Chldstn.1, -dfb.Chldss.1,
                -dfb.Chldtd.1, -dfb.Chldtm.1, -dfb.Chldtr.1, -dfb.Chldv.1,
                -dfb.Chldz.1, -dffit.1, -cov.r.1, -cook.d.1, -hat.1, -id,
                -residuals, -standardized.residuals, -studentized.residuals,
                -cooks.distance, -leverage, -covariance.ratios, -fitted)
nrow(spe)
```

We now repeat the analysis and begin by creating another boruta data set.

```{r likeac_4b_064, echo=T, eval = T, message=FALSE, warning=FALSE}
# create boruta data set
borutaspe <- spe
# inspect data
head(spe)
```

We can now begin with the statistical analysis of discourse *like* with speifying function. In a first step, we perform a Boruta analysis as a variable selection procedure to check which variables have any type of meaningful relationship with the use of discourse *like* with speifying function.

```{r likeac_4b_065, echo=T, eval = T, message=FALSE, warning=FALSE}
# load library
library(Boruta)
# run 1
boruta.spe <- Boruta(Specification ~.,data=borutaspe)
print(boruta.spe)
```

We remove variables that are confirmed as being unimportant and rerun the analysis.

```{r likeac_4b_066, echo=T, eval = T, message=FALSE, warning=FALSE}
borutaspe <- borutaspe %>%
  dplyr::select(-Spe_Freq)
# run 2
boruta.spe <- Boruta(Specification ~.,data=borutaspe)
print(boruta.spe)
```

We can visualize the results of the Boruta analysis.

```{r likeac_4b_067, echo=T, eval = T, message=FALSE, warning=FALSE}
plot(boruta.spe)
```

We can now proceed with the regression analysis.

```{r likeac_4b_068, echo=T, eval = T, message=FALSE, warning=FALSE}
# set options
options(contrasts  =c("contr.treatment", "contr.poly"))
data.dist <- datadist(spe)
options(datadist = "data.dist")
# create base glm line model
m0.glm = glm(Specification ~ 1, data = spe, family = binomial)
# create base glmm line model
m0.glmer = glmer(Specification ~ (1|Child), data = spe, family = binomial, 
                  control=glmerControl(optimizer="bobyqa"))
# compare AICs
aic.glmer<- AIC(logLik(m0.glmer))
aic.glm <- AIC(logLik(m0.glm))
aic.glmer; aic.glm
```

```{r likeac_4b_069, echo=T, eval = T, message=FALSE, warning=FALSE}
# test random effects
null.id = -2 * logLik(m0.glm) + 2 * logLik(m0.glmer)
pchisq(as.numeric(null.id), df=1, lower.tail=F) 
```

The glmm has a significantly better model fit compared to the glm model. We now check if Age is a significant predictor for speifying uses of discourse *like*.

```{r likeac_4b_070, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Age
m1.glm <- update(m0.glm, .~.+Age)
m1.glmer <- update(m0.glmer, .~.+Age)
anova(m1.glmer, m0.glmer, test = "Chi")     
Anova(m1.glmer, type = "III", test = "Chi")   
```
As Age is significant, we retain it in the model and proceed by adding Gender.

```{r likeac_4b_071, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Gender
ifelse(min(ftable(spe$Gender, spe$Specification)) == 0, "not possible", "possible")
m2.glm <- update(m1.glm, .~.+Gender)
vif(m2.glm)
m2.glmer <- update(m1.glmer, .~.+Gender)
anova(m2.glmer, m1.glmer, test = "Chi")     
Anova(m2.glmer, type = "III", test = "Chi")   
```

As Gender is not significant, we do not retain it in the model and proceed by adding SituationType.

```{r likeac_4b_072, echo=T, eval = T, message=FALSE, warning=FALSE}
# add SituationType
ifelse(min(ftable(spe$SituationType, spe$Specification)) == 0, "not possible", "possible")
m3.glm <- update(m1.glm, .~.+SituationType)
vif(m3.glm)
m3.glmer <- update(m1.glmer, .~.+SituationType)
anova(m3.glmer, m1.glmer, test = "Chi")     
Anova(m3.glmer, type = "III", test = "Chi")   
```

As SituationType is significant, we retain it in the model and proceed by adding Like_Freq.

```{r likeac_4b_073, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Like_Freq
m4.glm <- update(m3.glm, .~.+Like_Freq)
vif(m4.glm)
m4.glmer <- update(m3.glmer, .~.+Like_Freq)
anova(m4.glmer, m3.glmer, test = "Chi")     
Anova(m4.glmer, type = "III", test = "Chi")   
```

As Like_Freq is not significant, we do not retain it in the model and proceed by adding Participants.

```{r likeac_4b_074, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Participants
m5.glm <- update(m4.glm, .~.+ Participants)
vif(m5.glm)
m5.glmer <- update(m4.glmer, .~.+ Participants)
anova(m5.glmer, m4.glmer, test = "Chi")      
```

As Participants is not significant, we do not retain it in the model and proceed by adding all secondary or two-way interactions. We begin by adding Age*Gender.

```{r likeac_4b_075, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Age*Gender
m6.glm <- update(m4.glm, .~.+ Age*Gender)
vif(m6.glm)
m6.glmer <- update(m4.glmer, .~.+ Age*Gender)
anova(m6.glmer, m4.glmer, test = "Chi")     
Anova(m6.glmer, type = "III", test = "Chi")   
```

As the interaction between Age and Gender is not significant, we do not retain it in the model and proceed by adding the interaction between Age and SituationType.

```{r likeac_4b_076, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Age*SituationType
m7.glm <- update(m4.glm, .~.+ Age*SituationType)
vif(m7.glm)
```

Adding the interaction between Age and SituationType leads to unacceptable collinearity and we thus do not include it in the model. We proceed by adding the interaction between Age and Like_Freq.

```{r likeac_4b_077, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Age*Like_Freq
m8.glm <- update(m4.glm, .~.+ Age*Like_Freq)
vif(m8.glm)
m8.glmer <- update(m4.glmer, .~.+ Age*Like_Freq)
anova(m8.glmer, m4.glmer, test = "Chi")     
Anova(m8.glmer, type = "III", test = "Chi")   
```

The interaction between Age and Like_Freq is not significant and we thus do not retain it in the model. We proceed by adding the interaction between Age and Participants.

```{r likeac_4b_078, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Age*Participants
m9.glm <- update(m4.glm, .~.+ Age*Participants)
vif(m9.glm)
```

The interaction between Age and Participants leads to unacceptable collinearity and we thus do not include it in the model. We proceed by adding the interaction between Gender and SituationType.

```{r likeac_4b_079, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Gender*SituationType
m10.glm <- update(m4.glm, .~.+ Gender*SituationType)
vif(m10.glm)
m10.glmer <- update(m4.glmer, .~.+ Gender*SituationType)
anova(m10.glmer, m4.glmer, test = "Chi")     
```

The interaction between Gender and SituationType is not significant and we thus do not retain it in the model. We proceed by adding the interaction between Gender and Like_Freq.

```{r likeac_4b_080, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Gender*Like_Freq
m11.glm <- update(m4.glm, .~.+ Gender*Like_Freq)
vif(m11.glm)
m11.glmer <- update(m4.glmer, .~.+ Gender*Like_Freq)
anova(m11.glmer, m4.glmer, test = "Chi")      
```

The interaction between Gender and Like_Freq is not significant and we thus do not retain it in the model. We proceed by adding the interaction between Gender and Participants.

```{r likeac_4b_081, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Gender*Participants
m12.glm <- update(m4.glm, .~.+ Gender*Participants)
vif(m12.glm)
```

The interaction between Gender and Participants leads to unacceptable collinearity and we thus do not include it in the model. We proceed by adding the interaction between SituationType and Like_Freq.

```{r likeac_4b_082, echo=T, eval = T, message=FALSE, warning=FALSE}
# add SituationType*Like_Freq
m13.glm <- update(m4.glm, .~.+ SituationType*Like_Freq)
vif(m13.glm)
m13.glmer <- update(m4.glmer, .~.+ SituationType*Like_Freq)
anova(m13.glmer, m4.glmer, test = "Chi")      
```

The interaction between SituationType and Like_Freq is not significant and we thus do not retain it in the model.  We proceed by adding the interaction between SituationType and Participants.

```{r likeac_4b_083, echo=T, eval = T, message=FALSE, warning=FALSE}
# add SituationType*Participants
m14.glm <- update(m4.glm, .~.+ SituationType*Participants)
vif(m14.glm)
m14.glmer <- update(m4.glmer, .~.+ SituationType*Participants)
anova(m14.glmer, m4.glmer, test = "Chi")       
```

The interaction between SituationType and Participants  is not significant and we thus do not retain it in the model.  We proceed by adding the interaction between Like_Freq and Participants.

```{r likeac_4b_084, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Like_Freq*Participants
m15.glm <- update(m4.glm, .~.+ Like_Freq*Participants)
vif(m15.glm)
m15.glmer <- update(m4.glmer, .~.+ Like_Freq*Participants)
anova(m15.glmer, m4.glmer, test = "Chi")       
```

The interaction between Like_Freq and Participants  is not significant and we thus do not retain it in the model. We have arrived at a minimal adequate model and proceed with model diagnostics and create the diagnostic plots.

```{r likeac_4b_085, echo=T, eval = T, message=FALSE, warning=FALSE}
# start plotting
plot(m4.glmer, pch = 20, col = "black")         
```

We now check if the data contains data points that have an unacceptably high impact on the model by plotting the Cook's distance. To plot Cook's Distance, we create a glm object which also contains Turn as a predictor as it is included in the final glmer model in the random effect structure. This way, the predictions of the glm and the glmar model are identical.

```{r likeac_4b_086, echo=T, eval = T, message=FALSE, warning=FALSE}
m4b.glm <- update(m4.glm, .~.+ Child)
# determine a cutoff for data points that have D-values higher than 4/(n-k-1) 
cutoff <- 4/((nrow(spe)-length(m4b.glm$coefficients)-2))
cutoff
```

The Cook's distance plot names three data points that may cause issues. Also, if we apply the data driven cutoff for Cook's distance (0.001814882), we would retain only 55 data points which is unacceptable. 

We thus have to adapt the cutoff manually and plot the cook's distance values. 

```{r likeac_4b_087, echo=T, eval = T, message=FALSE, warning=FALSE}
# plot cook*s distance
plot(m4b.glm, which=4, cook.levels = cutoff) 
```

There are three 3 data points that are suggested as potential outliers which is why we add influence statistics to our data to get some more information about data points that may require removing.

```{r likeac_4b_088, echo=T, eval = T, message=FALSE, warning=FALSE}
# extract influence statistics
infl <- influence.measures(m4b.glm)       
# add infl. statistics to data
spe <- data.frame(spe, infl[[1]], infl[[2]]) 
```

We now add an index to the data to better identify problematic data points. Then, we order the data by the Cook's distance values and display the data to inspect the data points with the highest Cook's distance.

```{r likeac_4b_089, echo=T, eval = T, message=FALSE, warning=FALSE}
# create index for data
spe$id <- 1:nrow(spe)
spe <- spe[order(spe$cook.d, decreasing = T),]
head(spe)
```

The diagnostics do not indicate that we have to remove data points as, overall, the Cook's distance is distributed evenly and we proceed by extracting the model statistics, adding them to the data set, and creating additional model diagnostic plots. 

```{r likeac_4b_090, echo=T, eval = T, message=FALSE, warning=FALSE}
# add diagnostics
spe$residuals <- resid(m4b.glm)
spe$standardized.residuals <- rstandard(m4b.glm)
spe$studentized.residuals <- rstudent(m4b.glm)
spe$cooks.distance <- cooks.distance(m4b.glm)
spe$dffit <- dffits(m4b.glm)
spe$leverage <- hatvalues(m4b.glm)
spe$covariance.ratios <- covratio(m4b.glm)
spe$fitted <- m4b.glm$fitted.values
# plot diagnostics
p1 <- ggplot(spe, 
              aes(studentized.residuals)) +
  theme(legend.position = "none") +
  theme_set(theme_bw(base_size = 8))+ 
  geom_histogram(aes(y=..density..),
                 binwidth = 1,
                 colour="black",
                 fill="white") +
  labs(x = "Studentized Residual", y = "Density") + 
  stat_function(fun = dnorm, 
                args = list(mean = mean(spe$studentized.residuals, na.rm = TRUE), 
                            sd = sd(spe$studentized.residuals, na.rm = TRUE)), 
                colour = "red", size = 1)
p1
```

The diagnostic plots confirm that we will have to remove data points again. To identify these points, we plot the fitted values against the studentized residuals.

```{r likeac_4b_091, echo=T, eval = T, message=FALSE, warning=FALSE}
# plot diagnostics
p2 <- ggplot(spe, aes(fitted, studentized.residuals)) +
  geom_point() + 
  geom_smooth(method = "lm", colour = "Red")+
  theme_set(theme_bw(base_size = 8))+ 
  labs(x = "Fitted Values", 
       y = "Studentized Residual")
p2
```

```{r likeac_4b_092, echo=T, eval = T, message=FALSE, warning=FALSE}
# plot diagnostics
p3 <- qplot(sample = spe$studentized.residuals, stat="qq") + 
  theme_set(theme_bw(base_size = 8))+ 
  labs(x = "Theoretical Values", 
       y = "Observed Values")
p3
```

Now, we identify the data points that are identified as being problematic.

```{r likeac_4b_093, echo=T, eval = T, message=FALSE, warning=FALSE}
spe <- spe %>%
  dplyr::arrange(studentized.residuals)
# inspect data
spe[1:5,c(ncol(spe)-5:ncol(spe))]; spe[c(nrow(spe)-10:nrow(spe)), c(ncol(spe)-5:ncol(spe))]; nrow(spe)
```

We have now identified the problematic data points which are the points that have the IDs 202, 208, 313, 194, and 238. We remove these points as well as the diagnostic values and repeat the analysis.

```{r likeac_4b_094, echo=T, eval = T, message=FALSE, warning=FALSE}
rmv <- c(202, 208, 313, 194, 238)
# define not in
`%notin%` <- Negate(`%in%`)
spe <- spe %>%
  dplyr::filter(id %notin% rmv) %>%
  # remove diagnostic statistics
  dplyr::select(-dfb.1_, -dfb.Age, -dfb.SttT, -dfb.Lk_F, -dfb.Childl,
                -dfb.Chldll, -dfb.Chldnn, -dfb.Childst, -dfb.Chldbb,
                -dfb.Childbra, -dfb.Childbri, -dfb.Chldbrn, -dfb.Chldcs,
                -dfb.Chldcl, -dfb.Chldcn, -dfb.Chldct, -dfb.Childdav,
                -dfb.Childdev, -dfb.Childd, -dfb.Chldth, -dfb.Childg,
                -dfb.Chldgr, -dfb.Childn, -dfb.Chldjc, -dfb.Chldjm,
                -dfb.Childje, -dfb.Chldjb, -dfb.Chldjn, -dfb.Chldjr,
                -dfb.Childjes, -dfb.Childjo, -dfb.Chldjy, -dfb.Childjus,
                -dfb.Childkar, -dfb.Chldkv, -dfb.Childkur, -dfb.Childmr,
                -dfb.Chldmy, -dfb.Chldmg, -dfb.Chldml, -dfb.Chldmn,
                -dfb.Chldmrk, -dfb.Childp, -dfb.Chldpt, -dfb.Childras,
                -dfb.Chldrm, -dfb.Chldrl, -dfb.Chldrc, -dfb.Childros,
                -dfb.Chldsr, -dfb.Chldstn, -dfb.Chldss, -dfb.Chldtd,
                -dfb.Chldtm, -dfb.Chldtr, -dfb.Chldv, -dfb.Chldz, -dffit,
                -cov.r, -cook.d, -hat, -dfb.1_.1, -dfb.Age.1, -dfb.SttT.1,
                -dfb.Lk_F.1, -dfb.Childl.1, -dfb.Chldll.1, -dfb.Chldnn.1,
                -dfb.Childst.1, -dfb.Chldbb.1, -dfb.Childbra.1, 
                -dfb.Childbri.1, -dfb.Chldbrn.1, -dfb.Chldcs.1, -dfb.Chldcl.1,
                -dfb.Chldcn.1, -dfb.Chldct.1, -dfb.Childdav.1, -dfb.Childdev.1,
                -dfb.Childd.1, -dfb.Chldth.1, -dfb.Childg.1, -dfb.Chldgr.1,
                -dfb.Childn.1, -dfb.Chldjc.1, -dfb.Chldjm.1, -dfb.Childje.1,
                -dfb.Chldjb.1, -dfb.Chldjn.1, -dfb.Chldjr.1, -dfb.Childjes.1,
                -dfb.Childjo.1, -dfb.Chldjy.1, -dfb.Childjus.1, 
                -dfb.Childkar.1, -dfb.Chldkv.1, -dfb.Childkur.1, 
                -dfb.Childmr.1, -dfb.Chldmy.1, -dfb.Chldmg.1, -dfb.Chldml.1,
                -dfb.Chldmn.1, -dfb.Chldmrk.1, -dfb.Childp.1, -dfb.Chldpt.1,
                -dfb.Childras.1, -dfb.Chldrm.1, -dfb.Chldrl.1, -dfb.Chldrc.1,
                -dfb.Childros.1, -dfb.Chldsr.1, -dfb.Chldstn.1, -dfb.Chldss.1,
                -dfb.Chldtd.1, -dfb.Chldtm.1, -dfb.Chldtr.1, -dfb.Chldv.1,
                -dfb.Chldz.1, -dffit.1, -cov.r.1, -cook.d.1, -hat.1, -id,
                -residuals, -standardized.residuals, -studentized.residuals,
                -cooks.distance, -leverage, -covariance.ratios, -fitted)
nrow(spe)
```

We now repeat the analysis and begin by creating another boruta data set.

```{r likeac_4b_095, echo=T, eval = T, message=FALSE, warning=FALSE}
# create boruta data set
borutaspe <- spe
# inspect data
head(spe)
```

We can now begin with the statistical analysis of discourse *like* with speifying function. In a first step, we perform a Boruta analysis as a variable selection procedure to check which variables have any type of meaningful relationship with the use of discourse *like* with speifying function.

```{r likeac_4b_096, echo=T, eval = T, message=FALSE, warning=FALSE}
# load library
library(Boruta)
# run 1
boruta.spe <- Boruta(Specification ~.,data=borutaspe)
print(boruta.spe)
```

We remove variables that are confirmed as being unimportant and rerun the analysis.

```{r likeac_4b_097, echo=T, eval = T, message=FALSE, warning=FALSE}
borutaspe <- borutaspe %>%
  dplyr::select(-Spe_Freq)
# run 2
boruta.spe <- Boruta(Specification ~.,data=borutaspe)
print(boruta.spe)
```

We can visualize the results of the Boruta analysis.

```{r likeac_4b_098, echo=T, eval = T, message=FALSE, warning=FALSE}
png("images/Boruta_spe.png",  width = 1500, height = 750)
par(mar = c(14, 8, 4, 2) + 0.1)
plot(boruta.spe, cex.axis=2, las=2, xlab="", ylab = "", cex = 2, 
     col = c(rep("grey50", 6), rep("grey90",3)))
abline(v = 3.5, lty = "dashed")
mtext("Predictors", 1, line = 13, at = 7, cex = 3)
mtext("Control", 1, line = 13, at = 2, cex = 3)
mtext("Importance", 2, line = 2.5, at = 15, cex = 3, las = 0)
dev.off()
plot(boruta.spe, cex.axis=1, las=2, xlab="", ylab = "", cex = 1, 
     col = c(rep("grey50", 6), rep("grey90",3)))
abline(v = 3.5, lty = "dashed")
mtext("Predictors", 1, line = 4, at = 7, cex = 1)
mtext("Control", 1, line = 4, at = 2, cex = 1)
mtext("Importance", 2, line = 2.5, at = 15, cex = 1, las = 0)
par(mar = c(5, 4, 4, 2) + 0.1)
```

We can now proceed with the regression analysis.

```{r likeac_4b_099, echo=T, eval = T, message=FALSE, warning=FALSE}
# set options
options(contrasts  =c("contr.treatment", "contr.poly"))
data.dist <- datadist(spe)
options(datadist = "data.dist")
# create base glm line model
m0.glm = glm(Specification ~ 1, data = spe, family = binomial)
# create base glmm line model
m0.glmer = glmer(Specification ~ (1|Child), data = spe, family = binomial, 
                  control=glmerControl(optimizer="bobyqa"))
# compare AICs
aic.glmer<- AIC(logLik(m0.glmer))
aic.glm <- AIC(logLik(m0.glm))
aic.glmer; aic.glm
```

```{r likeac_4b_100, echo=T, eval = T, message=FALSE, warning=FALSE}
# test random effects
null.id = -2 * logLik(m0.glm) + 2 * logLik(m0.glmer)
pchisq(as.numeric(null.id), df=1, lower.tail=F) 
```

The glmm has a significantly better model fit compared to the glm model. We now check if Age is a significant predictor for speifying uses of discourse *like*.

```{r likeac_4b_101, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Age
m1.glm <- update(m0.glm, .~.+Age)
m1.glmer <- update(m0.glmer, .~.+Age)
anova(m1.glmer, m0.glmer, test = "Chi")     
Anova(m1.glmer, type = "III", test = "Chi")   
```
As Age is significant, we retain it in the model and proceed by adding Gender.

```{r likeac_4b_102, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Gender
ifelse(min(ftable(spe$Gender, spe$Specification)) == 0, "not possible", "possible")
m2.glm <- update(m1.glm, .~.+Gender)
vif(m2.glm)
m2.glmer <- update(m1.glmer, .~.+Gender)
anova(m2.glmer, m1.glmer, test = "Chi")      
```

As Gender is not significant, we do not retain it in the model and proceed by adding SituationType.

```{r likeac_4b_103, echo=T, eval = T, message=FALSE, warning=FALSE}
# add SituationType
ifelse(min(ftable(spe$SituationType, spe$Specification)) == 0, "not possible", "possible")
m3.glm <- update(m1.glm, .~.+SituationType)
vif(m3.glm)
m3.glmer <- update(m1.glmer, .~.+SituationType)
anova(m3.glmer, m1.glmer, test = "Chi")     
Anova(m3.glmer, type = "III", test = "Chi")   
```

As SituationType is significant, we retain it in the model and proceed by adding Like_Freq.

```{r likeac_4b_104, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Like_Freq
m4.glm <- update(m3.glm, .~.+Like_Freq)
vif(m4.glm)
m4.glmer <- update(m3.glmer, .~.+Like_Freq)
anova(m4.glmer, m3.glmer, test = "Chi")     
Anova(m4.glmer, type = "III", test = "Chi")   
```

As Like_Freq is not significant, we do not retain it in the model and proceed by adding Participants.

```{r likeac_4b_105, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Participants
m5.glm <- update(m4.glm, .~.+ Participants)
vif(m5.glm)
m5.glmer <- update(m4.glmer, .~.+ Participants)
anova(m5.glmer, m4.glmer, test = "Chi")      
```

As Participants is not significant, we do not retain it in the model and proceed by adding all secondary or two-way interactions. We begin by adding Age*Gender.

```{r likeac_4b_106, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Age*Gender
m6.glm <- update(m4.glm, .~.+ Age*Gender)
vif(m6.glm)
m6.glmer <- update(m4.glmer, .~.+ Age*Gender)
anova(m6.glmer, m4.glmer, test = "Chi")     
Anova(m6.glmer, type = "III", test = "Chi")   
```

As the interaction between Age and Gender is significant, we retain it in the model and proceed by adding the interaction between Age and SituationType.

```{r likeac_4b_107, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Age*SituationType
m7.glm <- update(m6.glm, .~.+ Age*SituationType)
vif(m7.glm)
```

Adding the interaction between Age and SituationType leads to unacceptable collinearity and we thus do not include it in the model. We proceed by adding the interaction between Age and Like_Freq.

```{r likeac_4b_108, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Age*Like_Freq
m8.glm <- update(m6.glm, .~.+ Age*Like_Freq)
vif(m8.glm)
m8.glmer <- update(m6.glmer, .~.+ Age*Like_Freq)
anova(m8.glmer, m6.glmer, test = "Chi")      
```

The interaction between Age and Like_Freq is not significant and we thus do not retain it in the model. We proceed by adding the interaction between Age and Participants.

```{r likeac_4b_109, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Age*Participants
m9.glm <- update(m6.glm, .~.+ Age*Participants)
vif(m9.glm)
```

The interaction between Age and Participants leads to unacceptable collinearity and we thus do not include it in the model. We proceed by adding the interaction between Gender and SituationType.

```{r likeac_4b_110, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Gender*SituationType
m10.glm <- update(m6.glm, .~.+ Gender*SituationType)
vif(m10.glm)
m10.glmer <- update(m6.glmer, .~.+ Gender*SituationType)
anova(m10.glmer, m6.glmer, test = "Chi")     
```

The interaction between Gender and SituationType is not significant and we thus do not retain it in the model. We proceed by adding the interaction between Gender and Like_Freq.

```{r likeac_4b_111, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Gender*Like_Freq
m11.glm <- update(m6.glm, .~.+ Gender*Like_Freq)
vif(m11.glm)
m11.glmer <- update(m6.glmer, .~.+ Gender*Like_Freq)
anova(m11.glmer, m6.glmer, test = "Chi")      
```

The interaction between Gender and Like_Freq is not significant and we thus do not retain it in the model. We proceed by adding the interaction between Gender and Participants.

```{r likeac_4b_112, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Gender*Participants
m12.glm <- update(m6.glm, .~.+ Gender*Participants)
vif(m12.glm)
```

The interaction between Gender and Participants leads to unacceptable collinearity and we thus do not include it in the model. We proceed by adding the interaction between SituationType and Like_Freq.

```{r likeac_4b_113, echo=T, eval = T, message=FALSE, warning=FALSE}
# add SituationType*Like_Freq
m13.glm <- update(m6.glm, .~.+ SituationType*Like_Freq)
vif(m13.glm)
m13.glmer <- update(m6.glmer, .~.+ SituationType*Like_Freq)
anova(m13.glmer, m6.glmer, test = "Chi")      
```

The interaction between SituationType and Like_Freq is not significant and we thus do not retain it in the model.  We proceed by adding the interaction between SituationType and Participants.

```{r likeac_4b_114, echo=T, eval = T, message=FALSE, warning=FALSE}
# add SituationType*Participants
m14.glm <- update(m6.glm, .~.+ SituationType*Participants)
vif(m14.glm)
m14.glmer <- update(m6.glmer, .~.+ SituationType*Participants)
anova(m14.glmer, m6.glmer, test = "Chi")       
```

The interaction between SituationType and Participants  is not significant and we thus do not retain it in the model.  We proceed by adding the interaction between Like_Freq and Participants.

```{r likeac_4b_115, echo=T, eval = T, message=FALSE, warning=FALSE}
# add Like_Freq*Participants
m15.glm <- update(m6.glm, .~.+ Like_Freq*Participants)
vif(m15.glm)
m15.glmer <- update(m6.glmer, .~.+ Like_Freq*Participants)
anova(m15.glmer, m6.glmer, test = "Chi")       
```

The interaction between Like_Freq and Participants  is not significant and we thus do not retain it in the model. We have arrived at a minimal adequate model and proceed with model diagnostics and create the diagnostic plots.

```{r likeac_4b_116, echo=T, eval = T, message=FALSE, warning=FALSE}
# start plotting
plot(m6.glmer, pch = 20, col = "black")         
```

We now check if the data contains data points that have an unacceptably high impact on the model by plotting the Cook's distance. To plot Cook's Distance, we create a glm object which also contains Turn as a predictor as it is included in the final glmer model in the random effect structure. This way, the predictions of the glm and the glmar model are identical.

```{r likeac_4b_117, echo=T, eval = T, message=FALSE, warning=FALSE}
m6b.glm <- update(m6.glm, .~.+ Child)
# determine a cutoff for data points that have D-values higher than 4/(n-k-1) 
cutoff <- 4/((nrow(spe)-length(m6b.glm$coefficients)-2))
cutoff
```

The Cook's distance plot names three data points that may cause issues. Also, if we apply the data driven cutoff for Cook's distance (0.001814882), we would retain only 55 data points which is unacceptable. 

We thus have to adapt the cutoff manually and plot the cook's distance values. 

```{r likeac_4b_118, echo=T, eval = T, message=FALSE, warning=FALSE}
# plot cook*s distance
plot(m6b.glm, which=4, cook.levels = cutoff) 
```

There are three 3 data points that are suggested as potential outliers which is why we add influence statistics to our data to get some more information about data points that may require removing.

```{r likeac_4b_119, echo=T, eval = T, message=FALSE, warning=FALSE}
# extract influence statistics
infl <- influence.measures(m6b.glm)       
# add infl. statistics to data
spe <- data.frame(spe, infl[[1]], infl[[2]]) 
```

We now add an index to the data to better identify problematic data points. Then, we order the data by the Cook's distance values and display the data to inspect the data points with the highest Cook's distance.

```{r likeac_4b_120, echo=T, eval = T, message=FALSE, warning=FALSE}
# create index for data
spe$id <- 1:nrow(spe)
spe <- spe[order(spe$cook.d, decreasing = T),]
head(spe)
```

The diagnostics do not indicate that we have to remove data points as, overall, the Cook's distance is distributed evenly and we proceed by extracting the model statistics, adding them to the data set, and creating additional model diagnostic plots. 

```{r likeac_4b_121, echo=T, eval = T, message=FALSE, warning=FALSE}
# add diagnostics
spe$residuals <- resid(m6b.glm)
spe$standardized.residuals <- rstandard(m6b.glm)
spe$studentized.residuals <- rstudent(m6b.glm)
spe$cooks.distance <- cooks.distance(m6b.glm)
spe$dffit <- dffits(m6b.glm)
spe$leverage <- hatvalues(m6b.glm)
spe$covariance.ratios <- covratio(m6b.glm)
spe$fitted <- m6b.glm$fitted.values
# plot diagnostics
p1 <- ggplot(spe, 
              aes(studentized.residuals)) +
  theme(legend.position = "none") +
  theme_set(theme_bw(base_size = 8))+ 
  geom_histogram(aes(y=..density..),
                 binwidth = 1,
                 colour="black",
                 fill="white") +
  labs(x = "Studentized Residual", y = "Density") + 
  stat_function(fun = dnorm, 
                args = list(mean = mean(spe$studentized.residuals, na.rm = TRUE), 
                            sd = sd(spe$studentized.residuals, na.rm = TRUE)), 
                colour = "red", size = 1)
p1
```

The diagnostic plots confirm that we will have to remove data points again. To identify these points, we plot the fitted values against the studentized residuals.

```{r likeac_4b_122, echo=T, eval = T, message=FALSE, warning=FALSE}
# plot diagnostics
p2 <- ggplot(spe, aes(fitted, studentized.residuals)) +
  geom_point() + 
  geom_smooth(method = "lm", colour = "Red")+
  theme_set(theme_bw(base_size = 8))+ 
  labs(x = "Fitted Values", 
       y = "Studentized Residual")
p2
```

```{r likeac_4b_123, echo=T, eval = T, message=FALSE, warning=FALSE}
# plot diagnostics
p3 <- qplot(sample = spe$studentized.residuals, stat="qq") + 
  theme_set(theme_bw(base_size = 8))+ 
  labs(x = "Theoretical Values", 
       y = "Observed Values")
p3
```

The additional model diagnostic plots do not look perfect. However, we proceed by inspecting the accuracy of the model summarizing the final minimal adequate model.

```{r likeac_4b_124, echo=T, eval = T, message=FALSE, warning=FALSE}
# calculate accuracy
spe$PredictedSpecificationProbability <- predict(m6.glmer, spe, type="response")
spe$PredictedSpecificationProbability <- ifelse(spe$PredictedSpecificationProbability >.5, 1, 0)
# load library
library(caret)
# create confusion matrix
confusionMatrix(as.factor(spe$PredictedSpecificationProbability), as.factor(spe$Specification))
```

The model has a very good accuracy (77.29% accuracy) against a base-line model accuracy of only 65.93% and it performs significantly better than  the  base-line model (p-value = 0.00000171). We call the model summary.

```{r likeac_4b_125, echo=T, eval = T, message=FALSE, warning=FALSE}
# call model summary
summary(m6.glmer)
```

We use the reported deviances to calculate the explained variance (nulldeviance-finaldeviance)/(nulldeviance). We also call the baseline model to extract the null deviance.

```{r likeac_4b_126, echo=T, eval = T, message=FALSE, warning=FALSE}
# call model summary
summary(m0.glmer)
```


```{r likeac_4b_127, echo=T, eval = T, message=FALSE, warning=FALSE}
# calculate explained variance
((453.8-416.8)/453.8)*100
```

The model explains 8.153372% more deviance than an intercept-only baseline model. We can now summarize the final minimal adequate model. To do so, we write a summary function for the mixed-effects binomial logistic regression model.

```{r nse_128, echo=T, eval = T, message=FALSE, warning=FALSE}
# write summary funtion
meblrm.summary <- function(glm0, glm1, glmer0, glmer1, dpvar, data) {
  p.nice <- function(z) {
    as.vector(unlist(sapply(z, function(w) {
      ifelse(w < .001, return("p < .001***"),
      ifelse(w < .01, return("p <  .01 **"),
      ifelse(w < .05, return("p <  .05  *"), 
      ifelse(w < .1, return("p <  .10(*)"), return("n.s."))))) } ))) }
  
  LLglm0 <- logLik(glm0)
  LLglmer0 <- logLik(glmer0)
  LLR01 <- as.vector(- 2 * (LLglm0 - LLglmer0))
  df <- attr(LLglmer0, "df") - attr(LLglm0, "df")
  p <- pchisq(LLR01, df, lower.tail = FALSE)
  headranef <- c("Group(s)", "Variance", "Std. Dev.", " ", "  ", "L.R. X2", "DF", "Pr", "Significance")
  ranef <- c(names(summary(glmer1)[[9]]), round(summary(glmer1)[[13]][[1]][[1]],2), 
  round(as.data.frame(VarCorr(glmer1))[[5]], 2), 
    "", "", round(LLR01, 2), df, round(p, 4), p.nice(p))

# take vif-mer function from https://github.com/aufrank/R-hacks/blob/master/mer-utils.R on 14th August, 2014
vif.mer <- function (fit) {
  ## adapted from rms::vif
  v <- vcov(fit)
  nam <- names(fixef(fit))
  ## exclude intercepts
  ns <- sum(1 * (nam == "Intercept" | nam == "(Intercept)"))
  if (ns > 0) {
  v <- v[-(1:ns), -(1:ns), drop = FALSE]
  nam <- nam[-(1:ns)]
  }
  d <- diag(v)^0.5
  v <- diag(solve(v/(d %o% d)))
  names(v) <- nam
  v
}
kappa.mer <- function (fit, scale = TRUE, center = FALSE,
  add.intercept = TRUE, exact = FALSE) {
  X <- fit@X
  nam <- names(fixef(fit))
  ## exclude intercepts
  nrp <- sum(1 * (nam == "(Intercept)"))
  if (nrp > 0) {
    X <- X[, -(1:nrp), drop = FALSE]
    nam <- nam[-(1:nrp)]
    }
  if (add.intercept) {
    X <- cbind(rep(1), scale(X, scale = scale, center = center))
    kappa(X, exact = exact)
    } else {
    kappa(scale(X, scale = scale, center = scale), exact = exact)
  }
}
colldiag.mer <- function (fit, scale = TRUE, center = FALSE,
  add.intercept = TRUE) {
  ## adapted from perturb::colldiag, method in Belsley, Kuh, and
  ## Welsch (1980). look for a high condition index (> 30) with
  ## more than one high variance propotion. see ?colldiag for more
  ## tips.
  result <- NULL
  if (center)
  add.intercept <- FALSE
  if (is.matrix(fit) || is.data.frame(fit)) {
    X <- as.matrix(fit)
    nms <- colnames(fit)
    }
  else if (class(fit) == "mer") {
    nms <- names(fixef(fit))
    X <- fit@X
      if (any(grepl("(Intercept)", nms))) {
      add.intercept <- FALSE
    }
  }
  X <- X[!is.na(apply(X, 1, all)), ]
  if (add.intercept) {
    X <- cbind(1, X)
    colnames(X)[1] <- "(Intercept)"
    }
  X <- scale(X, scale = scale, center = center)
  svdX <- svd(X)
  svdX$d
  condindx <- max(svdX$d)/svdX$d
  dim(condindx) <- c(length(condindx), 1)
  Phi = svdX$v %*% diag(1/svdX$d)
  Phi <- t(Phi^2)
  pi <- prop.table(Phi, 2)
  colnames(condindx) <- "cond.index"
  if (!is.null(nms)) {
    rownames(condindx) <- nms
    colnames(pi) <- nms
    rownames(pi) <- nms
  } else {
    rownames(condindx) <- 1:length(condindx)
    colnames(pi) <- 1:ncol(pi)
    rownames(pi) <- 1:nrow(pi)
  }
  result <- data.frame(cbind(condindx, pi))
  zapsmall(result)
}
maxcorr.mer <- function (fit, exclude.intercept = TRUE) {
  so <- summary(fit)
  corF <- so@vcov@factors$correlation
  nam <- names(fixef(fit))
  ## exclude intercepts
  ns <- sum(1 * (nam == "Intercept" | nam == "(Intercept)"))
  if (ns > 0 & exclude.intercept) {
    corF <- corF[-(1:ns), -(1:ns), drop = FALSE]
    nam <- nam[-(1:ns)]
  }
  corF[!lower.tri(corF)] <- 0
  maxCor <- max(corF)
  minCor <- min(corF)
  if (abs(maxCor) > abs(minCor)) {
    zapsmall(maxCor)
  } else {
    zapsmall(minCor)
  }
}

# continue with setting up table
  coefs <- summary(glmer1)[[10]]

  se <- sqrt(diag(vcov(glmer1)))
  cilwr <- fixef(glmer1) - 1.96 * se
  ciupr <- fixef(glmer1) + 1.96 * se
  coef.df <- data.frame(
    round(coefs[, 1], 2),
    c("", round(vif.mer(glmer1), 2)),
    round(exp(coefs[, 1]), 2),
    round(exp(cilwr), 2),
    round(exp(ciupr), 2),
    round(coefs[, 2], 2),
    round(coefs[, 3], 2),
    round(coefs[, 4], 4),
    p.nice(coefs[, 4]))
  colnames(coef.df) <- c(colnames(coefs)[1],
    "VIF",
    "OddsRatio",
    "CI(2.5%)",
    "CI(97.5%)",
    colnames(coefs)[2],
    colnames(coefs)[3],
    colnames(coefs)[4],
    "Significance")
    
  coef.df <- rbind(colnames(coef.df), coef.df)
  coef.df <- as.data.frame(coef.df)
  colnames(coef.df) <- c(colnames(coefs)[1],
    "VIF",
    "OddsRatio",
    "CI(2.5%)",
    "CI(97.5%)",
    colnames(coefs)[2],
    colnames(coefs)[3],
    colnames(coefs)[4],
    "Significance")
    
  mdl.statz <- c("", "", "", "", "", "", "", "", "Value")
  groups <- c("", "", "", "", "", "", "", "", summary(glmer1)[[9]][[1]])
  nbcases <- c("", "", "", "", "", "", "", "", length(fitted(glmer1)))
  obs0 <- c("", "", "", "", "", "", "", "", sum(dpvar == 0))
  obs1  <- c("", "", "", "", "", "", "", "", sum(dpvar == 1))
  resdev <- c("", "", "", "", "", "", "", "", round(summary(glmer1)[[3]][[1]][[8]], 2))

  logisticPseudoR2s <- function(glm0, glmer0, glmer1) {
    dev <- deviance(glmer1)
    nullDev <- deviance(glmer0)
    modelN <-  length(fitted(glmer1))
    
    nullDev.glm <- glm0$null.deviance
    R.l.glm <-  1-dev/nullDev.glm
    R.cs.glm <- 1-exp(-(nullDev.glm-dev)/modelN)
    R.n.glm <- R.cs.glm/(1-(exp(-(nullDev.glm/modelN))))
    
    return(c(R.l.glm,      # Hosmer and Lemeshow R^2
      R.cs.glm,            # Cox and Snell R^2
      R.n.glm))            # Nagelkerke R^2
  }

  r2s <- logisticPseudoR2s(glm0, glmer0, glmer1)
  R2Nagelkerke <- c("", "","", "", "", "", "", "",round(r2s[[3]], 3))
  R2HosmerLemeshow <- c("", "","", "", "", "", "", "",round(r2s[[1]], 3))
  R2CoxSnell <- c("", "","", "", "", "", "", "",round(r2s[[2]], 3))

  probs <- predict(glmer1, data, type = "response")
  spestatz <- somers2(probs, as.numeric(dpvar)-1)

  C <- c("", "", "", "", "", "", "", "",round(spestatz[[1]], 3))
  Dxy <- c("", "", "", "", "", "", "", "",round(spestatz[[2]], 3))
  AIC <- c("", "", "", "", "", "", "", "", round(summary(glmer1)[[14]][[1]], 2))
  BIC <- c("", "", "", "", "", "", "", "", round(summary(glmer1)[[14]][[2]], 2))


  dpvarneg <- sapply(dpvar, function(x) ifelse(x == 1, 0, 1))
  correct <- sum(dpvar * (predict(glmer1, type = "response") >= 0.5)) + sum(dpvarneg * (predict(glmer1, type="response") < 0.5))
  tot <- length(dpvar)
  predict.acc <- (correct/tot)*100 

  Accuracy <- c("", "", "", "", "", "", "", "", paste(round(predict.acc, 2), "%", sep = "", collapse = ""))
  
  L0 <- logLik(glm0)
  L1 <- logLik(glmer1)
  L01 <- as.vector(- 2 * (L0 - L1))
  df <- attr(L1, "df") - attr(L0, "df")
    
  ModelLikelihoodRatioTest <- c("", "", "", "", "",
    paste("L.R. X2: ", round(L01, 2), sep = "", collapse = ""),
    paste("DF: ", df, sep = "", collapse = ""),
    paste("p-value: ", round(pchisq(L01, df, lower.tail = FALSE), 5), sep = "", collapse = ""),
    paste("sig: ", p.nice(pchisq(L01, df, lower.tail = FALSE)), sep = "", collapse = ""))

  ranef.tb <- rbind(ranef)
  ranef.df <- as.data.frame(ranef.tb)
  colnames(ranef.df) <- colnames(coef.df)
    
  gblstz.tb <- rbind(mdl.statz, groups, nbcases, obs0, obs1, resdev,
    R2Nagelkerke, R2HosmerLemeshow, R2CoxSnell, C, Dxy, AIC, BIC, Accuracy, ModelLikelihoodRatioTest)
  gblstz.df <- as.data.frame(gblstz.tb)
  colnames(gblstz.df) <- colnames(coef.df)

  blr.tb <- rbind(ranef.df, coef.df, gblstz.df)
  colnames(blr.tb) <- headranef
  rownames(blr.tb) <- c("Random Effect(s)", "Fixed Effect(s)", rownames(coefs),
    "Model statistics", "Number of Groups", "Number of cases in model", 
    "Observed misses", "Observed successes",
    "Residual deviance", "R2 (Nagelkerke)", "R2 (Hosmer & Lemeshow)",
    "R2 (Cox & Snell)", "C", "Somers' Dxy", "AIC", "BIC", "Prediction accuracy", "Model Likelihood Ratio Test")
  blr.df <- as.data.frame(blr.tb)
return(blr.df)
}
```

Now we can apply the summary function to the models that we have created.

```{r likeac_4b_129, echo=T, eval = T, message=FALSE, warning=FALSE}
# set up summary table
mblrm_spe <- meblrm.summary(m0.glm, m6.glm, m0.glmer, m6.glmer, spe$Specification, spe) 
# save results to disc
write.table(mblrm_spe, "datatables/mblrm_spe_pp.txt", sep="\t")
mblrm_spe
```

We now save summary of the final minimal adequate model and check other model summaries.

```{r likeac_4b_130, echo=T, eval = T, message=FALSE, warning=FALSE}
# Anova summary
mblrm_spe_Anova <- Anova(m6.glmer, type = "III", test = "Chi")
mblrm_spe_Anova
```

We save this new summary and store the effect sizes of the predictors.

```{r likeac_4b_131, echo=T, eval = T, message=FALSE, warning=FALSE}
# save results to disc
write.table(mblrm_spe_Anova, "datatables/mblrm_spe_Anova_pp.txt", sep="\t")
# extract effect sizes
effectage <- anova(m0.glmer, m1.glmer, test = "Chi")
effectsituationtype <- anova(m1.glmer, m3.glmer, test = "Chi")
effectlikefreq <- anova(m3.glmer, m4.glmer, test = "Chi")
effectagegender <- anova(m4.glmer, m6.glmer, test = "Chi")
effectage; effectsituationtype; effectlikefreq; effectagegender
```

We now create a data set for plotting the results of the analysis.

```{r likeac_4b_132, echo=T, eval = T, message=FALSE, warning=FALSE}
#summary(spe$Age)
Age <- seq(3.6, 10.5, .1)
#table(spe$SituationType)
SituationType <- names(table(spe$SituationType))
#table(spe$Gender)
Gender <- names(table(spe$Gender))
#summary(spe$Like_Freq)
Like_Freq <- seq(1, 6.4, .1)
# extract Child
randomtb <- ranef(m6.glmer)
rndmchild <- as.vector(unlist(randomtb$`Child`))
child <- as.vector(unlist(rownames(randomtb$`Child`)))
Child <- as.vector(unlist(rownames(randomtb$`Child`)))
# 
pd <- data.frame(
  rep(Age, times =  
      (length(SituationType)*length(Gender)*length(Like_Freq)*length(Child))),
  rep(SituationType, each = length(Age), times =  
      (length(Gender)*length(Like_Freq)*length(Child))),
  rep(Gender, each = (length(Age)*length(SituationType)), 
      times = (length(Like_Freq)*length(Child))), 
  rep(Like_Freq, each = (length(Age)*length(SituationType)*
                          length(Gender)), times = length(Child)), 
  rep(Child, each = (length(Age)*length(SituationType)*
                          length(Gender)*Like_Freq))
  )
colnames(pd) <- c("Age", "SituationType", "Gender", "Like_Freq", "Child")
pd$SituationType <- factor(pd$SituationType)
pd$Gender <- factor(pd$Gender)
pd$PredictedSpecificationProbability <- predict(m6.glmer, pd, type = "response")
head(pd)
```

Plot the effects

```{r likeac_4b_133, echo=T, eval = T, message=FALSE, warning=FALSE}
p4 <- ggplot(pd, aes(Age, PredictedSpecificationProbability, gropu = Gender, linetype = Gender, color = Gender)) +
    facet_grid( ~ SituationType) + 
  geom_smooth(se = F) +  
  guides(color=guide_legend(override.aes=list(fill=NA))) +
  scale_linetype_manual(values=c("dotted", "solid"),
                        name="Gender",
                        breaks = c("female", "male"), 
                        labels = c("female", "male")) +
  scale_colour_manual(values=c("grey20",  "grey60"),
                      name="Gender", 
                      breaks=c("female", "male"), 
                      labels = c("female", "male")) +
  theme_set(theme_bw(base_size = 15)) +
     theme(legend.position="top", legend.title = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank()) +
  coord_cartesian(ylim = c(0, 1)) +
  theme(legend.position="top") +
    scale_x_continuous(name = "Age of Child",
                     breaks = seq(3, 11, 1),
                     labels= seq(3, 11, 1)) +
  labs(x = "Age of Child", y = "Predicted Probability \n of specifying discourse like") +
  scale_color_manual(values = c("grey30", "grey30")) +
  ggsave(file = paste(imageDirectory,"PredictedSpecification_pp.png",sep="/"), 
       height = 4,  width = 7, dpi = 320)
p4
```

```{r likeac_4b_134, echo=T, eval = T, message=FALSE, warning=FALSE}
p5 <- ggplot(pd, aes(Like_Freq, PredictedSpecificationProbability)) +
#  stat_summary(fun.y = mean, geom = "point", aes(group= Position)) +          
#  stat_summary(fun.data = mean_cl_boot, geom = "errorbar", width = 0.2) +
  stat_smooth(se = T, color = "gray20") +
  #geom_smooth(color = "gray20", se = T) +  
  theme_set(theme_bw(base_size = 15)) +
     theme(legend.position="top", legend.title = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank()) +
  coord_cartesian(ylim = c(0, 1)) +
  theme(legend.position="none") +
    scale_x_continuous(name = "Frequency of discourse like by caregivers",
                     breaks = seq(0, 6.4, 1),
                     labels= seq(0, 6.4, 1)) +
  labs(x = "Frequency of discourse like in caregivers' input", y = "Predicted Probability \n of specifying discourse like") +
  scale_color_manual(values = c("grey30", "grey30")) +
  ggsave(file = paste(imageDirectory,"PredictedSpecification_LikeFreq_pp.png",sep="/"), 
       height = 4,  width = 7, dpi = 320)
p5
```

In addition, we use the effects package to plot the effects to check if our effect plots are correct.

```{r likeac_4b_135, echo=T, eval = T, message=FALSE, warning=FALSE}
library(effects)
png("images/effectsfinalmodel_spe.png",  width = 960, height = 480) 
plot(allEffects(m6.glmer), type="response", ylim=c(0,1), grid=TRUE, 
     lines = list(col="black",
                  lty = 1,
                  confint=list(style="bars",
                               col = "grey80")), 
     ylab = "Probability (Specifying use of discourse like)")
dev.off()
plot(allEffects(m6.glmer), type="response", ylim=c(0,1), grid=TRUE, 
     lines = list(col="black",
                  lty = 1,
                  confint=list(style="bars",
                               col = "grey80")), 
     ylab = "Probability (Specifying use of discourse like)")
```

```{r likeac_4b_136, echo=T, eval = T, message=FALSE, warning=FALSE}
randomtb <- ranef(m6.glmer)
rndmchild <- as.vector(unlist(randomtb$`Child`))
child <- as.vector(unlist(rownames(randomtb$`Child`)))
rndmchildtb <- data.frame(child, rndmchild)
colnames(rndmchildtb) <- c("Child", "Intercept")
rndmchildtb <- rndmchildtb[order(rndmchildtb$Intercept, decreasing = T),]
rndmchildtb
```

```{r likeac_4b_137, echo=T, eval = T, message=FALSE, warning=FALSE}
p6 <- ggplot(rndmchildtb, aes(Child, Intercept)) +
  geom_point(aes(reorder(Child, -Intercept, fun = Intercept), y=Intercept)) +
  coord_cartesian(ylim = c(-1.5, 1.5)) +
  theme_set(theme_bw(base_size = 15)) +
  theme(legend.position="none", 
        axis.text.x = element_text(size=15, angle=90),
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank()) +
  scale_x_discrete(breaks = rndmchildtb$Child[seq(1,length(rndmchildtb$Child),3)]) +
  labs(x = "Child \n(only selected children displayed)", y = "Adjustment to Intercept")
ggsave(file = paste(imageDirectory,"RandomChildSpe.png",sep="/"), 
       height = 5,  width = 7.5,  dpi = 320)
# activate (remove #) to show
p6
```

The effect plots from the effects package confirm our customized effect plot and we have thus reached the end of Part 4b of the analysis.
